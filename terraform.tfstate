{
  "version": 4,
  "terraform_version": "1.2.8",
  "serial": 10,
  "lineage": "0c92479c-85a3-6681-4753-ec0ce529d948",
  "outputs": {},
  "resources": [
    {
      "module": "module.helm-argocd",
      "mode": "managed",
      "type": "helm_release",
      "name": "argo-cd",
      "provider": "module.helm-argocd.provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "argo-cd",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": true,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "argo-cd",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "v2.4.11",
                "chart": "argo-cd",
                "name": "argo-cd",
                "namespace": "argo-cd",
                "revision": 1,
                "values": "{\"apiVersionOverrides\":{\"autoscaling\":\"\",\"certmanager\":\"\",\"ingress\":\"\"},\"applicationSet\":{\"affinity\":{},\"args\":{\"debug\":false,\"dryRun\":false,\"enableLeaderElection\":false,\"metricsAddr\":\":8080\",\"policy\":\"sync\",\"probeBindAddr\":\":8081\"},\"enabled\":true,\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"logFormat\":\"\",\"logLevel\":\"\",\"metrics\":{\"enabled\":false,\"service\":{\"annotations\":{},\"labels\":{},\"portName\":\"http-metrics\",\"servicePort\":8085},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"applicationset-controller\",\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"podSecurityContext\":{},\"priorityClassName\":\"\",\"replicaCount\":1,\"resources\":{},\"securityContext\":{},\"service\":{\"annotations\":{},\"labels\":{},\"port\":7000,\"portName\":\"webhook\"},\"serviceAccount\":{\"annotations\":{},\"create\":true,\"name\":\"\"},\"tolerations\":[],\"webhook\":{\"ingress\":{\"annotations\":{},\"enabled\":false,\"extraPaths\":[],\"hosts\":[],\"ingressClassName\":\"\",\"labels\":{},\"pathType\":\"Prefix\",\"paths\":[\"/api/webhook\"],\"tls\":[]}}},\"configs\":{\"clusterCredentials\":[],\"credentialTemplates\":{},\"credentialTemplatesAnnotations\":{},\"gpgKeys\":{},\"gpgKeysAnnotations\":{},\"knownHosts\":{\"data\":{\"ssh_known_hosts\":\"bitbucket.org ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAubiN81eDcafrgMeLzaFPsw2kNvEcqTKl/VqLat/MaB33pZy0y3rJZtnqwR2qOOvbwKZYKiEO1O6VqNEBxKvJJelCq0dTXWT5pbO2gDXC6h6QDXCaHo6pOHGPUy+YBaGQRGuSusMEASYiWunYN0vCAI8QaXnWMXNMdFP3jHAJH0eDsoiGnLPBlBp4TNm6rYI74nMzgz3B9IikW4WVK+dc8KZJZWYjAuORU3jc1c/NPskD2ASinf8v3xnfXeukU0sJ5N6m5E8VLjObPEO+mN2t/FZTMZLiFqPWc/ALSqnMnnhwrNi2rbfg/rd/IpL8Le3pSBne8+seeFVBoGqzHM9yXw==\\ngithub.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=\\ngithub.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl\\ngithub.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ==\\ngitlab.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFSMqzJeV9rUzU4kWitGjeR4PWSa29SPqJ1fVkhtj3Hw9xjLVXVYrU9QlYWrOLXBpQ6KWjbjTDTdDkoohFzgbEY=\\ngitlab.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAfuCHKVTjquxvt6CM6tdG4SLp1Btn/nOeHHE5UOzRdf\\ngitlab.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCsj2bNKTBSpIYDEGk9KxsGh3mySTRgMtXL583qmBpzeQ+jqCMRgBqB98u3z++J1sKlXHWfM9dyhSevkMwSbhoR8XIq/U0tCNyokEi/ueaBMCvbcTHhO7FcwzY92WK4Yt0aGROY5qX2UKSeOvuP4D6TPqKF1onrSzH9bx9XUf2lEdWT/ia1NEKjunUqu1xOB/StKDHMoX4/OKyIzuS0q/T1zOATthvasJFoPrAjkohTyaDUz2LN5JoH839hViyEG82yB+MjcFV5MU3N1l1QL3cVUCh93xSaua1N85qivl+siMkPGbO5xR/En4iEY6K2XPASUEMaieWVNTRCtJ4S8H+9\\nssh.dev.azure.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H\\nvs-ssh.visualstudio.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H\\n\"}},\"knownHostsAnnotations\":{},\"repositories\":{},\"repositoriesAnnotations\":{},\"secret\":{\"annotations\":{},\"argocdServerAdminPassword\":\"\",\"argocdServerAdminPasswordMtime\":\"\",\"argocdServerTlsConfig\":{},\"bitbucketServerSecret\":\"\",\"bitbucketUUID\":\"\",\"createSecret\":true,\"extra\":{},\"githubSecret\":\"\",\"gitlabSecret\":\"\",\"gogsSecret\":\"\"},\"styles\":\"\",\"tlsCerts\":{},\"tlsCertsAnnotations\":{}},\"controller\":{\"affinity\":{},\"args\":{\"appHardResyncPeriod\":\"0\",\"appResyncPeriod\":\"180\",\"operationProcessors\":\"10\",\"repoServerTimeoutSeconds\":\"60\",\"selfHealTimeout\":\"5\",\"statusProcessors\":\"20\"},\"clusterAdminAccess\":{\"enabled\":true},\"clusterRoleRules\":{\"enabled\":false,\"rules\":[]},\"containerPort\":8082,\"containerSecurityContext\":{},\"env\":[],\"envFrom\":[],\"extraArgs\":[],\"extraContainers\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"initContainers\":[],\"livenessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"logFormat\":\"\",\"logLevel\":\"\",\"metrics\":{\"applicationLabels\":{\"enabled\":false,\"labels\":[]},\"enabled\":false,\"rules\":{\"enabled\":false,\"spec\":[]},\"service\":{\"annotations\":{},\"labels\":{},\"portName\":\"http-metrics\",\"servicePort\":8082},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"application-controller\",\"nodeSelector\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{}},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"readinessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicas\":1,\"resources\":{},\"service\":{\"annotations\":{},\"labels\":{},\"port\":8082,\"portName\":\"https-controller\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"argocd-application-controller\"},\"tolerations\":[],\"topologySpreadConstraints\":[],\"volumeMounts\":[],\"volumes\":[]},\"crds\":{\"annotations\":{},\"install\":true,\"keep\":true},\"createAggregateRoles\":false,\"dex\":{\"affinity\":{},\"containerPortGrpc\":5557,\"containerPortHttp\":5556,\"containerPortMetrics\":5558,\"containerSecurityContext\":{},\"enabled\":true,\"env\":[],\"envFrom\":[],\"extraArgs\":[],\"extraContainers\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"ghcr.io/dexidp/dex\",\"tag\":\"v2.30.2\"},\"imagePullSecrets\":[],\"initContainers\":[],\"initImage\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"livenessProbe\":{\"enabled\":false,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"metrics\":{\"enabled\":false,\"service\":{\"annotations\":{},\"labels\":{},\"portName\":\"http-metrics\"},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"dex-server\",\"nodeSelector\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{}},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":false,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"resources\":{},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"argocd-dex-server\"},\"servicePortGrpc\":5557,\"servicePortGrpcName\":\"grpc\",\"servicePortHttp\":5556,\"servicePortHttpName\":\"http\",\"servicePortMetrics\":5558,\"tolerations\":[],\"topologySpreadConstraints\":[],\"volumeMounts\":[{\"mountPath\":\"/shared\",\"name\":\"static-files\"}],\"volumes\":[{\"emptyDir\":{},\"name\":\"static-files\"}]},\"externalRedis\":{\"existingSecret\":\"\",\"host\":\"\",\"password\":\"\",\"port\":6379,\"secretAnnotations\":{}},\"extraObjects\":[],\"fullnameOverride\":\"\",\"global\":{\"additionalLabels\":{},\"hostAliases\":[],\"image\":{\"imagePullPolicy\":\"IfNotPresent\",\"repository\":\"quay.io/argoproj/argocd\",\"tag\":\"\"},\"imagePullSecrets\":[],\"logging\":{\"format\":\"text\",\"level\":\"info\"},\"networkPolicy\":{\"create\":false,\"defaultDenyIngress\":false},\"podAnnotations\":{},\"podLabels\":{},\"securityContext\":{}},\"kubeVersionOverride\":\"\",\"nameOverride\":\"argocd\",\"notifications\":{\"affinity\":{},\"argocdUrl\":null,\"bots\":{\"slack\":{\"affinity\":{},\"containerSecurityContext\":{},\"enabled\":false,\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"nodeSelector\":{},\"resources\":{},\"securityContext\":{\"runAsNonRoot\":true},\"service\":{\"annotations\":{},\"port\":80,\"type\":\"LoadBalancer\"},\"serviceAccount\":{\"annotations\":{},\"create\":true,\"name\":\"argocd-notifications-bot\"},\"tolerations\":[],\"updateStrategy\":{\"type\":\"Recreate\"}}},\"cm\":{\"create\":true},\"containerSecurityContext\":{},\"context\":{},\"enabled\":true,\"extraArgs\":[],\"extraEnv\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"logFormat\":\"\",\"logLevel\":\"\",\"metrics\":{\"enabled\":false,\"port\":9001,\"service\":{\"annotations\":{},\"labels\":{},\"portName\":\"http-metrics\"},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":false,\"scheme\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"notifications-controller\",\"nodeSelector\":{},\"notifiers\":{},\"podAnnotations\":{},\"podLabels\":{},\"resources\":{},\"secret\":{\"annotations\":{},\"create\":true,\"items\":{}},\"securityContext\":{\"runAsNonRoot\":true},\"serviceAccount\":{\"annotations\":{},\"create\":true,\"name\":\"argocd-notifications-controller\"},\"subscriptions\":[],\"templates\":{},\"tolerations\":[],\"triggers\":{},\"updateStrategy\":{\"type\":\"Recreate\"}},\"openshift\":{\"enabled\":false},\"redis\":{\"affinity\":{},\"containerPort\":6379,\"containerSecurityContext\":{},\"enabled\":true,\"env\":[],\"envFrom\":[],\"extraArgs\":[],\"extraContainers\":[],\"image\":{\"imagePullPolicy\":\"IfNotPresent\",\"repository\":\"public.ecr.aws/docker/library/redis\",\"tag\":\"7.0.4-alpine\"},\"imagePullSecrets\":[],\"initContainers\":[],\"metrics\":{\"containerPort\":9121,\"enabled\":false,\"image\":{\"imagePullPolicy\":\"IfNotPresent\",\"repository\":\"public.ecr.aws/bitnami/redis-exporter\",\"tag\":\"1.26.0-debian-10-r2\"},\"resources\":{},\"service\":{\"annotations\":{},\"clusterIP\":\"None\",\"labels\":{},\"portName\":\"http-metrics\",\"servicePort\":9121,\"type\":\"ClusterIP\"},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"redis\",\"nodeSelector\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{}},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"resources\":{},\"securityContext\":{\"runAsNonRoot\":true,\"runAsUser\":999},\"service\":{\"annotations\":{},\"labels\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":false,\"create\":false,\"name\":\"\"},\"servicePort\":6379,\"tolerations\":[],\"topologySpreadConstraints\":[],\"volumeMounts\":[],\"volumes\":[]},\"redis-ha\":{\"enabled\":false,\"exporter\":{\"enabled\":true},\"haproxy\":{\"enabled\":true,\"metrics\":{\"enabled\":true}},\"image\":{\"tag\":\"7.0.4-alpine\"},\"persistentVolume\":{\"enabled\":false},\"redis\":{\"config\":{\"save\":\"\\\"\\\"\"},\"masterGroupName\":\"argocd\"},\"topologySpreadConstraints\":{\"enabled\":false,\"maxSkew\":\"\",\"topologyKey\":\"\",\"whenUnsatisfiable\":\"\"}},\"repoServer\":{\"affinity\":{},\"autoscaling\":{\"behavior\":{},\"enabled\":false,\"maxReplicas\":5,\"minReplicas\":1,\"targetCPUUtilizationPercentage\":50,\"targetMemoryUtilizationPercentage\":50},\"clusterAdminAccess\":{\"enabled\":false},\"clusterRoleRules\":{\"enabled\":false,\"rules\":[]},\"containerPort\":8081,\"containerSecurityContext\":{},\"copyutil\":{\"resources\":{}},\"env\":[],\"envFrom\":[],\"extraArgs\":[],\"extraContainers\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"initContainers\":[],\"livenessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"logFormat\":\"\",\"logLevel\":\"\",\"metrics\":{\"enabled\":false,\"service\":{\"annotations\":{},\"labels\":{},\"portName\":\"http-metrics\",\"servicePort\":8084},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"repo-server\",\"nodeSelector\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{}},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"rbac\":[],\"readinessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicas\":1,\"resources\":{},\"service\":{\"annotations\":{},\"labels\":{},\"port\":8081,\"portName\":\"https-repo-server\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"\"},\"tolerations\":[],\"topologySpreadConstraints\":[],\"volumeMounts\":[],\"volumes\":[]},\"server\":{\"GKEbackendConfig\":{\"enabled\":false,\"spec\":{}},\"GKEfrontendConfig\":{\"enabled\":false,\"spec\":{}},\"GKEmanagedCertificate\":{\"domains\":[\"argocd.example.com\"],\"enabled\":false},\"affinity\":{},\"autoscaling\":{\"behavior\":{},\"enabled\":false,\"maxReplicas\":5,\"minReplicas\":1,\"targetCPUUtilizationPercentage\":50,\"targetMemoryUtilizationPercentage\":50},\"certificate\":{\"additionalHosts\":[],\"domain\":\"argocd.example.com\",\"duration\":\"\",\"enabled\":false,\"issuer\":{\"group\":\"\",\"kind\":\"\",\"name\":\"\"},\"renewBefore\":\"\",\"secretName\":\"argocd-server-tls\"},\"clusterAdminAccess\":{\"enabled\":true},\"config\":{\"admin.enabled\":\"true\",\"application.instanceLabelKey\":\"argocd.argoproj.io/instance\",\"exec.enabled\":\"false\",\"server.rbac.log.enforce.enable\":\"false\",\"url\":\"\"},\"configAnnotations\":{},\"configEnabled\":true,\"containerPort\":8080,\"containerSecurityContext\":{},\"env\":[],\"envFrom\":[],\"extensions\":{\"contents\":[],\"enabled\":false,\"image\":{\"imagePullPolicy\":\"IfNotPresent\",\"repository\":\"ghcr.io/argoproj-labs/argocd-extensions\",\"tag\":\"v0.1.0\"},\"resources\":{}},\"extraArgs\":[\"--insecure\"],\"extraContainers\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"ingress\":{\"annotations\":{},\"enabled\":false,\"extraPaths\":[],\"hosts\":[],\"https\":false,\"ingressClassName\":\"\",\"labels\":{},\"pathType\":\"Prefix\",\"paths\":[\"/\"],\"tls\":[]},\"ingressGrpc\":{\"annotations\":{},\"awsALB\":{\"backendProtocolVersion\":\"HTTP2\",\"serviceType\":\"NodePort\"},\"enabled\":false,\"extraPaths\":[],\"hosts\":[],\"https\":false,\"ingressClassName\":\"\",\"isAWSALB\":false,\"labels\":{},\"pathType\":\"Prefix\",\"paths\":[\"/\"],\"tls\":[]},\"initContainers\":[],\"lifecycle\":{},\"livenessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"logFormat\":\"\",\"logLevel\":\"\",\"metrics\":{\"enabled\":false,\"service\":{\"annotations\":{},\"labels\":{},\"portName\":\"http-metrics\",\"servicePort\":8083},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"server\",\"nodeSelector\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{}},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"rbacConfig\":{},\"rbacConfigAnnotations\":{},\"rbacConfigCreate\":true,\"readinessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicas\":1,\"resources\":{},\"route\":{\"annotations\":{},\"enabled\":false,\"hostname\":\"\",\"termination_policy\":\"None\",\"termination_type\":\"passthrough\"},\"service\":{\"annotations\":{},\"externalIPs\":[],\"externalTrafficPolicy\":\"\",\"labels\":{},\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"namedTargetPort\":true,\"nodePortHttp\":30080,\"nodePortHttps\":30443,\"servicePortHttp\":80,\"servicePortHttpName\":\"http\",\"servicePortHttps\":443,\"servicePortHttpsName\":\"https\",\"sessionAffinity\":\"\",\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"argocd-server\"},\"staticAssets\":{\"enabled\":true},\"tolerations\":[],\"topologySpreadConstraints\":[],\"volumeMounts\":[],\"volumes\":[]}}",
                "version": "5.4.1"
              }
            ],
            "name": "argo-cd",
            "namespace": "argo-cd",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://argoproj.github.io/argo-helm",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "## Argo CD configuration\n## Ref: https://github.com/argoproj/argo-cd\n##\n\n# -- Provide a name in place of `argocd`\nnameOverride: argocd\n# -- String to fully override `\"argo-cd.fullname\"`\nfullnameOverride: \"\"\n# -- Override the Kubernetes version, which is used to evaluate certain manifests\nkubeVersionOverride: \"\"\n\n## Custom resource configuration\ncrds:\n  # -- Install and upgrade CRDs\n  install: true\n  # -- Keep CRDs on chart uninstall\n  keep: true\n  # -- Annotations to be added to all CRDs\n  annotations: {}\n\nglobal:\n  image:\n    # -- If defined, a repository applied to all Argo CD deployments\n    repository: quay.io/argoproj/argocd\n    # -- Overrides the global Argo CD image tag whose default is the chart appVersion\n    tag: \"\"\n    # -- If defined, a imagePullPolicy applied to all Argo CD deployments\n    imagePullPolicy: IfNotPresent\n  logging:\n    # -- Set the global logging format. Either: `text` or `json`\n    format: text\n    # -- Set the global logging level. One of: `debug`, `info`, `warn` or `error`\n    level: info\n  # -- Annotations for the all deployed pods\n  podAnnotations: {}\n  # -- Labels for the all deployed pods\n  podLabels: {}\n  # -- Toggle and define securityContext. See [values.yaml]\n  securityContext: {}\n  #  runAsUser: 999\n  #  runAsGroup: 999\n  #  fsGroup: 999\n\n  # -- If defined, uses a Secret to pull an image from a private Docker registry or repository\n  imagePullSecrets: []\n  # -- Mapping between IP and hostnames that will be injected as entries in the pod's hosts files\n  hostAliases: []\n  # - ip: 10.20.30.40\n  #   hostnames:\n  #   - git.myhostname\n\n  # -- Additional labels to add to all resources\n  additionalLabels: {}\n    # app: argo-cd\n\n  networkPolicy:\n    # -- Create NetworkPolicy objects for all components\n    create: false\n    # -- Default deny all ingress traffic\n    defaultDenyIngress: false\n\n# Override APIVersions\n# If you want to template helm charts but cannot access k8s API server\n# you can set api versions here\napiVersionOverrides:\n  # -- String to override apiVersion of certmanager resources rendered by this helm chart\n  certmanager: \"\" # cert-manager.io/v1\n  # -- String to override apiVersion of ingresses rendered by this helm chart\n  ingress: \"\" # networking.k8s.io/v1beta1\n  # -- String to override apiVersion of autoscaling rendered by this helm chart\n  autoscaling: \"\" # autoscaling/v2\n\n# -- Create clusterroles that extend existing clusterroles to interact with argo-cd crds\n## Ref: https://kubernetes.io/docs/reference/access-authn-authz/rbac/#aggregated-clusterroles\ncreateAggregateRoles: false\n\n# -- Array of extra K8s manifests to deploy\nextraObjects: []\n  # - apiVersion: secrets-store.csi.x-k8s.io/v1\n  #   kind: SecretProviderClass\n  #   metadata:\n  #     name: argocd-secrets-store\n  #   spec:\n  #     provider: aws\n  #     parameters:\n  #       objects: |\n  #         - objectName: \"argocd\"\n  #           objectType: \"secretsmanager\"\n  #           jmesPath:\n  #               - path: \"client_id\"\n  #                 objectAlias: \"client_id\"\n  #               - path: \"client_secret\"\n  #                 objectAlias: \"client_secret\"\n  #     secretObjects:\n  #     - data:\n  #       - key: client_id\n  #         objectName: client_id\n  #       - key: client_secret\n  #         objectName: client_secret\n  #       secretName: argocd-secrets-store\n  #       type: Opaque\n  #       labels:\n  #         app.kubernetes.io/part-of: argocd\n\n## Controller\ncontroller:\n  # -- Application controller name string\n  name: application-controller\n\n  image:\n    # -- Repository to use for the application controller\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\"\n    # -- Tag to use for the application controller\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\"\n    # -- Image pull policy for the application controller\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n\n  # -- The number of application controller pods to run.\n  # Additional replicas will cause sharding of managed clusters across number of replicas.\n  replicas: 1\n\n  ## Application controller commandline flags\n  args:\n    # -- define the application controller `--status-processors`\n    statusProcessors: \"20\"\n    # -- define the application controller `--operation-processors`\n    operationProcessors: \"10\"\n    # -- define the application controller `--app-hard-resync`\n    appHardResyncPeriod: \"0\"\n    # -- define the application controller `--app-resync`\n    appResyncPeriod: \"180\"\n    # -- define the application controller `--self-heal-timeout-seconds`\n    selfHealTimeout: \"5\"\n    # -- define the application controller `--repo-server-timeout-seconds`\n    repoServerTimeoutSeconds: \"60\"\n\n  # -- Application controller log format. Either `text` or `json`\n  # @default -- `\"\"` (defaults to global.logging.format)\n  logFormat: \"\"\n  # -- Application controller log level. One of: `debug`, `info`, `warn` or `error`\n  # @default -- `\"\"` (defaults to global.logging.level)\n  logLevel: \"\"\n\n  # -- Additional command line arguments to pass to application controller\n  extraArgs: []\n\n  # -- Environment variables to pass to application controller\n  env: []\n\n  # -- envFrom to pass to application controller\n  # @default -- `[]` (See [values.yaml])\n  envFrom: []\n  # - configMapRef:\n  #     name: config-map-name\n  # - secretRef:\n  #     name: secret-name\n\n  # -- Annotations to be added to application controller pods\n  podAnnotations: {}\n\n  # -- Labels to be added to application controller pods\n  podLabels: {}\n\n  # -- Application controller container-level security context\n  containerSecurityContext:\n    {}\n    # capabilities:\n    #   drop:\n    #     - all\n    # readOnlyRootFilesystem: true\n    # runAsNonRoot: true\n\n  # -- Application controller listening port\n  containerPort: 8082\n\n  ## Readiness and liveness probes for default backend\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n  ##\n  readinessProbe:\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n  livenessProbe:\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n\n  # -- Additional volumeMounts to the application controller main container\n  volumeMounts: []\n\n  # -- Additional volumes to the application controller pod\n  volumes: []\n\n  ## Controller service configuration\n  service:\n    # -- Application controller service annotations\n    annotations: {}\n    # -- Application controller service labels\n    labels: {}\n    # -- Application controller service port\n    port: 8082\n    # -- Application controller service port name\n    portName: https-controller\n\n  # -- [Node selector]\n  nodeSelector: {}\n  # -- [Tolerations] for use with node taints\n  tolerations: []\n  # -- Assign custom [affinity] rules to the deployment\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to the application controller\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n  # - maxSkew: 1\n  #   topologyKey: topology.kubernetes.io/zone\n  #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Priority class for the application controller pods\n  priorityClassName: \"\"\n\n  # -- Resource limits and requests for the application controller pods\n  resources: {}\n  #  limits:\n  #    cpu: 500m\n  #    memory: 512Mi\n  #  requests:\n  #    cpu: 250m\n  #    memory: 256Mi\n\n  serviceAccount:\n    # -- Create a service account for the application controller\n    create: true\n    # -- Service account name\n    name: argocd-application-controller\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  ## Application controller metrics configuration\n  metrics:\n    # -- Deploy metrics service\n    enabled: false\n    applicationLabels:\n      # -- Enables additional labels in argocd_app_labels metric\n      enabled: false\n      # -- Additional labels\n      labels: []\n    service:\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port\n      servicePort: 8082\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor interval\n      interval: 30s\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\" # \"monitoring\"\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n    rules:\n      # -- Deploy a PrometheusRule for the application controller\n      enabled: false\n      # -- PrometheusRule.Spec for the application controller\n      spec: []\n      # - alert: ArgoAppMissing\n      #   expr: |\n      #     absent(argocd_app_info)\n      #   for: 15m\n      #   labels:\n      #     severity: critical\n      #   annotations:\n      #     summary: \"[Argo CD] No reported applications\"\n      #     description: \u003e\n      #       Argo CD has not reported any applications data for the past 15 minutes which\n      #       means that it must be down or not functioning properly.  This needs to be\n      #       resolved for this cloud to continue to maintain state.\n      # - alert: ArgoAppNotSynced\n      #   expr: |\n      #     argocd_app_info{sync_status!=\"Synced\"} == 1\n      #   for: 12h\n      #   labels:\n      #     severity: warning\n      #   annotations:\n      #     summary: \"[{{`{{$labels.name}}`}}] Application not synchronized\"\n      #     description: \u003e\n      #       The application [{{`{{$labels.name}}`}} has not been synchronized for over\n      #       12 hours which means that the state of this cloud has drifted away from the\n      #       state inside Git.\n    #   selector:\n    #     prometheus: kube-prometheus\n    #   namespace: monitoring\n    #   additionalLabels: {}\n\n  ## Enable if you would like to grant rights to Argo CD to deploy to the local Kubernetes cluster.\n  clusterAdminAccess:\n    # -- Enable RBAC for local cluster deployments\n    enabled: true\n\n  ## Enable this and set the rules: to whatever custom rules you want for the Cluster Role resource.\n  ## Defaults to off\n  clusterRoleRules:\n    # -- Enable custom rules for the application controller's ClusterRole resource\n    enabled: false\n    # -- List of custom rules for the application controller's ClusterRole resource\n    rules: []\n\n  # -- Additional containers to be added to the application controller pod\n  extraContainers: []\n\n  # -- Init containers to add to the application controller pod\n  ## If your target Kubernetes cluster(s) require a custom auth provider executable\n  ## you could use this (and the same in the server pod) to bootstrap\n  ## that executable into your Argo CD container\n  initContainers: []\n  #  - name: download-tools\n  #    image: alpine:3.8\n  #    command: [sh, -c]\n  #    args:\n  #      - wget -qO- https://get.helm.sh/helm-v2.16.1-linux-amd64.tar.gz | tar -xvzf - \u0026\u0026\n  #        mv linux-amd64/helm /custom-tools/\n  #    volumeMounts:\n  #      - mountPath: /custom-tools\n  #        name: custom-tools\n  #  volumeMounts:\n  #  - mountPath: /usr/local/bin/helm\n  #    name: custom-tools\n  #    subPath: helm\n\n  pdb:\n    # -- Labels to be added to application controller pdb\n    labels: {}\n    # -- Annotations to be added to application controller pdb\n    annotations: {}\n\n    # -- Deploy a Poddisruptionbudget for the application controller\n    enabled: false\n    # minAvailable: 1\n    # maxUnavailable: 0\n\n  # -- Secrets with credentials to pull images from a private registry\n  imagePullSecrets: []\n\n## Dex\ndex:\n  # -- Enable dex\n  enabled: true\n  # -- Dex name\n  name: dex-server\n\n  # -- Additional command line arguments to pass to the Dex server\n  extraArgs: []\n\n  metrics:\n    # -- Deploy metrics service\n    enabled: false\n    service:\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor interval\n      interval: 30s\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\" # \"monitoring\"\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n\n  image:\n    # -- Dex image repository\n    repository: ghcr.io/dexidp/dex\n    # -- Dex image tag\n    tag: v2.30.2\n    # -- Dex imagePullPolicy\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n  initImage:\n    # -- Argo CD init image repository\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\"\n    # -- Argo CD init image tag\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\"\n    # -- Argo CD init image imagePullPolicy\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n\n  # -- Environment variables to pass to the Dex server\n  env: []\n\n  # -- envFrom to pass to the Dex server\n  # @default -- `[]` (See [values.yaml])\n  envFrom: []\n  # - configMapRef:\n  #     name: config-map-name\n  # - secretRef:\n  #     name: secret-name\n\n  # -- Annotations to be added to the Dex server pods\n  podAnnotations: {}\n\n  # -- Labels to be added to the Dex server pods\n  podLabels: {}\n\n  ## Probes for Dex server\n  ## Supported from Dex \u003e= 2.28.0\n  livenessProbe:\n    # -- Enable Kubernetes liveness probe for Dex \u003e= 2.28.0\n    enabled: false\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n  readinessProbe:\n    # -- Enable Kubernetes readiness probe for Dex \u003e= 2.28.0\n    enabled: false\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n\n  serviceAccount:\n    # -- Create dex service account\n    create: true\n    # -- Dex service account name\n    name: argocd-dex-server\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  # -- Additional volumeMounts to the dex main container\n  volumeMounts:\n    - name: static-files\n      mountPath: /shared\n\n  # -- Additional volumes to the dex pod\n  volumes:\n    - name: static-files\n      emptyDir: {}\n\n  # -- Extra volumes to the dex pod\n  extraVolumes: []\n\n  # -- Extra volumeMounts to the dex pod\n  extraVolumeMounts: []\n\n  # -- Container port for HTTP access\n  containerPortHttp: 5556\n  # -- Service port for HTTP access\n  servicePortHttp: 5556\n  # -- Service port name for HTTP access\n  servicePortHttpName: http\n  # -- Container port for gRPC access\n  containerPortGrpc: 5557\n  # -- Service port for gRPC access\n  servicePortGrpc: 5557\n  # -- Service port name for gRPC access\n  servicePortGrpcName: grpc\n  # -- Container port for metrics access\n  containerPortMetrics: 5558\n  # -- Service port for metrics access\n  servicePortMetrics: 5558\n\n  # -- [Node selector]\n  nodeSelector: {}\n  # -- [Tolerations] for use with node taints\n  tolerations: []\n  # -- Assign custom [affinity] rules to the deployment\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to dex\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n  # - maxSkew: 1\n  #   topologyKey: topology.kubernetes.io/zone\n  #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Priority class for dex\n  priorityClassName: \"\"\n\n  # -- Dex container-level security context\n  containerSecurityContext:\n    {}\n    # capabilities:\n    #   drop:\n    #     - all\n    # readOnlyRootFilesystem: true\n\n# -- Resource limits and requests for dex\n  resources: {}\n  #  limits:\n  #    cpu: 50m\n  #    memory: 64Mi\n  #  requests:\n  #    cpu: 10m\n  #    memory: 32Mi\n\n  # -- Additional containers to be added to the dex pod\n  extraContainers: []\n\n  # -- Init containers to add to the dex pod\n  initContainers: []\n  #  - name: download-tools\n  #    image: alpine:3.8\n  #    command: [sh, -c]\n  #    args:\n  #      - wget -qO- https://get.helm.sh/helm-v2.16.1-linux-amd64.tar.gz | tar -xvzf - \u0026\u0026\n  #        mv linux-amd64/helm /custom-tools/\n  #    volumeMounts:\n  #      - mountPath: /custom-tools\n  #        name: custom-tools\n  #  volumeMounts:\n  #  - mountPath: /usr/local/bin/helm\n  #    name: custom-tools\n  #    subPath: helm\n\n  pdb:\n    # -- Labels to be added to Dex server pdb\n    labels: {}\n    # -- Annotations to be added to Dex server pdb\n    annotations: {}\n\n    # -- Deploy a Poddisruptionbudget for the Dex server\n    enabled: false\n    # minAvailable: 1\n    # maxUnavailable: 0\n\n  # -- Secrets with credentials to pull images from a private registry\n  imagePullSecrets: []\n\n## Redis\nredis:\n  # -- Enable redis\n  enabled: true\n  # -- Redis name\n  name: redis\n\n  image:\n    # -- Redis repository\n    repository: public.ecr.aws/docker/library/redis\n    # -- Redis tag\n    tag: 7.0.4-alpine\n    # -- Redis imagePullPolicy\n    imagePullPolicy: IfNotPresent\n\n  # -- Additional command line arguments to pass to redis-server\n  extraArgs: []\n  # - --bind\n  # - \"0.0.0.0\"\n\n  # -- Redis container port\n  containerPort: 6379\n  # -- Redis service port\n  servicePort: 6379\n\n  # -- Environment variables to pass to the Redis server\n  env: []\n\n  # -- envFrom to pass to the Redis server\n  # @default -- `[]` (See [values.yaml])\n  envFrom: []\n  # - configMapRef:\n  #     name: config-map-name\n  # - secretRef:\n  #     name: secret-name\n\n  # -- Annotations to be added to the Redis server pods\n  podAnnotations: {}\n\n  # -- Labels to be added to the Redis server pods\n  podLabels: {}\n\n  # -- [Node selector]\n  nodeSelector: {}\n  # -- [Tolerations] for use with node taints\n  tolerations: []\n  # -- Assign custom [affinity] rules to the deployment\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to redis\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n  # - maxSkew: 1\n  #   topologyKey: topology.kubernetes.io/zone\n  #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Priority class for redis\n  priorityClassName: \"\"\n\n  # -- Redis container-level security context\n  containerSecurityContext:\n    {}\n    # capabilities:\n    #   drop:\n    #     - all\n    # readOnlyRootFilesystem: true\n\n  # -- Redis pod-level security context\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 999\n\n  serviceAccount:\n    # -- Create a service account for the redis pod\n    create: false\n    # -- Service account name for redis pod\n    name: \"\"\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: false\n\n  # -- Resource limits and requests for redis\n  resources: {}\n  #  limits:\n  #    cpu: 200m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 64Mi\n\n  # -- Additional volumeMounts to the redis container\n  volumeMounts: []\n  # -- Additional volumes to the redis pod\n  volumes: []\n\n  # -- Additional containers to be added to the redis pod\n  extraContainers: []\n\n  # -- Init containers to add to the redis pod\n  initContainers: []\n  #  - name: download-tools\n  #    image: alpine:3.8\n  #    command: [sh, -c]\n  #    args:\n  #      - wget -qO- https://get.helm.sh/helm-v2.16.1-linux-amd64.tar.gz | tar -xvzf - \u0026\u0026\n  #        mv linux-amd64/helm /custom-tools/\n  #    volumeMounts:\n  #      - mountPath: /custom-tools\n  #        name: custom-tools\n  #  volumeMounts:\n  #  - mountPath: /usr/local/bin/helm\n  #    name: custom-tools\n  #    subPath: helm\n\n  service:\n    # -- Redis service annotations\n    annotations: {}\n    # -- Additional redis service labels\n    labels: {}\n\n  metrics:\n    # -- Deploy metrics service and redis-exporter sidecar\n    enabled: false\n    image:\n      # -- redis-exporter image repository\n      repository: public.ecr.aws/bitnami/redis-exporter\n      # -- redis-exporter image tag\n      tag: 1.26.0-debian-10-r2\n      # -- redis-exporter image PullPolicy\n      imagePullPolicy: IfNotPresent\n    # -- Port to use for redis-exporter sidecar\n    containerPort: 9121\n    # -- Resource limits and requests for redis-exporter sidecar\n    resources: {}\n      # limits:\n      #   cpu: 50m\n      #   memory: 64Mi\n      # requests:\n      #   cpu: 10m\n      #   memory: 32Mi\n    service:\n      # -- Metrics service type\n      type: ClusterIP\n      # -- Metrics service clusterIP. `None` makes a \"headless service\" (no virtual IP)\n      clusterIP: None\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port\n      servicePort: 9121\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Interval at which metrics should be scraped\n      interval: 30s\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\" # \"monitoring\"\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n\n  pdb:\n    # -- Labels to be added to Redis server pdb\n    labels: {}\n    # -- Annotations to be added to Redis server pdb\n    annotations: {}\n\n    # -- Deploy a Poddisruptionbudget for the Redis server\n    enabled: false\n    # minAvailable: 1\n    # maxUnavailable: 0\n\n  # -- Secrets with credentials to pull images from a private registry\n  imagePullSecrets: []\n\n# This key configures Redis-HA subchart and when enabled (redis-ha.enabled=true)\n# the custom redis deployment is omitted\n# Check the redis-ha chart for more properties\nredis-ha:\n  # -- Enables the Redis HA subchart and disables the custom Redis single node deployment\n  enabled: false\n  exporter:\n    # -- If `true`, the prometheus exporter sidecar is enabled\n    enabled: true\n  persistentVolume:\n    # -- Configures persistency on Redis nodes\n    enabled: false\n  redis:\n    # -- Redis convention for naming the cluster group: must match `^[\\\\w-\\\\.]+$` and can be templated\n    masterGroupName: argocd\n    # -- Any valid redis config options in this section will be applied to each server (see `redis-ha` chart)\n    # @default -- See [values.yaml]\n    config:\n      # -- Will save the DB if both the given number of seconds and the given number of write operations against the DB occurred. `\"\"`  is disabled\n      # @default -- `'\"\"'`\n      save: '\"\"'\n  haproxy:\n    # -- Enabled HAProxy LoadBalancing/Proxy\n    enabled: true\n    metrics:\n      # -- HAProxy enable prometheus metric scraping\n      enabled: true\n  image:\n    # -- Redis tag\n    tag: 7.0.4-alpine\n\n  ## https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  topologySpreadConstraints:\n    # -- Enable Redis HA topology spread constraints\n    enabled: false\n    # -- Max skew of pods tolerated\n    # @default -- `\"\"` (defaults to `1`)\n    maxSkew: \"\"\n    # -- Topology key for spread\n    # @default -- `\"\"` (defaults to `topology.kubernetes.io/zone`)\n    topologyKey: \"\"\n    # -- Enforcement policy, hard or soft\n    # @default -- `\"\"` (defaults to `ScheduleAnyway`)\n    whenUnsatisfiable: \"\"\n\n# External Redis parameters\nexternalRedis:\n  # -- External Redis server host\n  host: \"\"\n  # -- External Redis password\n  password: \"\"\n  # -- External Redis server port\n  port: 6379\n  # -- The name of an existing secret with Redis credentials (must contain key `redis-password`).\n  # When it's set, the `externalRedis.password` parameter is ignored\n  existingSecret: \"\"\n  # -- External Redis Secret annotations\n  secretAnnotations: {}\n\n## Server\nserver:\n  # -- Argo CD server name\n  name: server\n\n  # -- The number of server pods to run\n  replicas: 1\n\n  autoscaling:\n    # -- Enable Horizontal Pod Autoscaler ([HPA]) for the Argo CD server\n    enabled: false\n    # -- Minimum number of replicas for the Argo CD server [HPA]\n    minReplicas: 1\n    # -- Maximum number of replicas for the Argo CD server [HPA]\n    maxReplicas: 5\n    # -- Average CPU utilization percentage for the Argo CD server [HPA]\n    targetCPUUtilizationPercentage: 50\n    # -- Average memory utilization percentage for the Argo CD server [HPA]\n    targetMemoryUtilizationPercentage: 50\n    # -- Configures the scaling behavior of the target in both Up and Down directions.\n    # This is only available on HPA apiVersion `autoscaling/v2beta2` and newer\n    behavior: {}\n      # scaleDown:\n      #  stabilizationWindowSeconds: 300\n      #  policies:\n      #   - type: Pods\n      #     value: 1\n      #     periodSeconds: 180\n      # scaleUp:\n      #   stabilizationWindowSeconds: 300\n      #   policies:\n      #   - type: Pods\n      #     value: 2\n      #     periodSeconds: 60\n  image:\n    # -- Repository to use for the Argo CD server\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\" # defaults to global.image.repository\n    # -- Tag to use for the Argo CD server\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\" # defaults to global.image.tag\n    # -- Image pull policy for the Argo CD server\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\" # IfNotPresent\n\n  # -- Additional command line arguments to pass to Argo CD server\n  extraArgs: \n    - --insecure\n\n  # This flag is used to either remove or pass the CLI flag --staticassets /shared/app to the Argo CD server app\n  staticAssets:\n    # -- Disable deprecated flag `--staticassets`\n    enabled: true\n\n  # -- Environment variables to pass to Argo CD server\n  env: []\n\n  # -- envFrom to pass to Argo CD server\n  # @default -- `[]` (See [values.yaml])\n  envFrom: []\n  # - configMapRef:\n  #     name: config-map-name\n  # - secretRef:\n  #     name: secret-name\n\n  # -- Specify postStart and preStop lifecycle hooks for your argo-cd-server container\n  lifecycle: {}\n\n  # -- Argo CD server log format: Either `text` or `json`\n  # @default -- `\"\"` (defaults to global.logging.format)\n  logFormat: \"\"\n  # -- Argo CD server log level. One of: `debug`, `info`, `warn` or `error`\n  # @default -- `\"\"` (defaults to global.logging.level)\n  logLevel: \"\"\n\n  # -- Annotations to be added to server pods\n  podAnnotations: {}\n\n  # -- Labels to be added to server pods\n  podLabels: {}\n\n  # -- Configures the server port\n  containerPort: 8080\n\n  ## Readiness and liveness probes for default backend\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n  ##\n  readinessProbe:\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n  livenessProbe:\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n\n  # -- Additional volumeMounts to the server main container\n  volumeMounts: []\n\n  # -- Additional volumes to the server pod\n  volumes: []\n\n  # -- [Node selector]\n  nodeSelector: {}\n  # -- [Tolerations] for use with node taints\n  tolerations: []\n  # -- Assign custom [affinity] rules to the deployment\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to the Argo CD server\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n  # - maxSkew: 1\n  #   topologyKey: topology.kubernetes.io/zone\n  #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Priority class for the Argo CD server\n  priorityClassName: \"\"\n\n  # -- Servers container-level security context\n  containerSecurityContext:\n    {}\n    # capabilities:\n    #   drop:\n    #     - all\n    # readOnlyRootFilesystem: true\n\n  # -- Resource limits and requests for the Argo CD server\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 50m\n  #    memory: 64Mi\n\n  ## Certificate configuration\n  certificate:\n    # -- Deploy a Certificate resource (requires cert-manager)\n    enabled: false\n    # -- Certificate primary domain (commonName)\n    domain: argocd.example.com\n    # -- The requested 'duration' (i.e. lifetime) of the Certificate. Value must be in units accepted by Go time.ParseDuration\n    duration: \"\"\n    # -- How long before the currently issued certificate's expiry cert-manager should renew the certificate. Value must be in units accepted by Go time.ParseDuration\n    renewBefore: \"\"\n    issuer:\n      # -- Certificate issuer group. Set if using an external issuer. Eg. `cert-manager.io`\n      group: \"\"\n      # -- Certificate issuer kind. Either `Issuer` or `ClusterIssuer`\n      kind: \"\"\n      # -- Certificate isser name. Eg. `letsencrypt`\n      name: \"\"\n    # -- Certificate manager additional hosts\n    additionalHosts: []\n    # -- The name of the Secret that will be automatically created and managed by this Certificate resource\n    secretName: argocd-server-tls\n\n  ## Server service configuration\n  service:\n    # -- Server service annotations\n    annotations: {}\n    # -- Server service labels\n    labels: {}\n    # -- Server service type\n    type: ClusterIP\n    # -- Server service http port for NodePort service type (only if `server.service.type` is set to \"NodePort\")\n    nodePortHttp: 30080\n    # -- Server service https port for NodePort service type (only if `server.service.type` is set to \"NodePort\")\n    nodePortHttps: 30443\n    # -- Server service http port\n    servicePortHttp: 80\n    # -- Server service https port\n    servicePortHttps: 443\n    # -- Server service http port name, can be used to route traffic via istio\n    servicePortHttpName: http\n    # -- Server service https port name, can be used to route traffic via istio\n    servicePortHttpsName: https\n    # -- Use named target port for argocd\n    ## Named target ports are not supported by GCE health checks, so when deploying argocd on GKE\n    ## and exposing it via GCE ingress, the health checks fail and the load balancer returns a 502.\n    namedTargetPort: true\n    # -- LoadBalancer will get created with the IP specified in this field\n    loadBalancerIP: \"\"\n    # -- Source IP ranges to allow access to service from\n    loadBalancerSourceRanges: []\n    # -- Server service external IPs\n    externalIPs: []\n    # -- Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints\n    externalTrafficPolicy: \"\"\n    # -- Used to maintain session affinity. Supports `ClientIP` and `None`\n    sessionAffinity: \"\"\n\n  ## Server metrics service configuration\n  metrics:\n    # -- Deploy metrics service\n    enabled: false\n    service:\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port\n      servicePort: 8083\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor interval\n      interval: 30s\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\"  # monitoring\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n\n  serviceAccount:\n    # -- Create server service account\n    create: true\n    # -- Server service account name\n    name: argocd-server\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  ingress:\n    # -- Enable an ingress resource for the Argo CD server\n    enabled: false\n    # -- Additional ingress annotations\n    annotations: {}\n    # -- Additional ingress labels\n    labels: {}\n    # -- Defines which ingress controller will implement the resource\n    ingressClassName: \"\"\n\n    # -- List of ingress hosts\n    ## Argo Ingress.\n    ## Hostnames must be provided if Ingress is enabled.\n    ## Secrets must be manually created in the namespace\n    hosts:\n      []\n      # - argocd.example.com\n\n    # -- List of ingress paths\n    paths:\n      - /\n    # -- Ingress path type. One of `Exact`, `Prefix` or `ImplementationSpecific`\n    pathType: Prefix\n    # -- Additional ingress paths\n    extraPaths:\n      []\n      # - path: /*\n      #   backend:\n      #     serviceName: ssl-redirect\n      #     servicePort: use-annotation\n      ## for Kubernetes \u003e=1.19 (when \"networking.k8s.io/v1\" is used)\n      # - path: /*\n      #   pathType: Prefix\n      #   backend:\n      #     service:\n      #       name: ssl-redirect\n      #       port:\n      #         name: use-annotation\n\n    # -- Ingress TLS configuration\n    tls:\n      []\n      # - secretName: argocd-tls-certificate\n      #   hosts:\n      #     - argocd.example.com\n\n    # -- Uses `server.service.servicePortHttps` instead `server.service.servicePortHttp`\n    https: false\n\n  # dedicated ingress for gRPC as documented at\n  # Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/\n  ingressGrpc:\n    # -- Enable an ingress resource for the Argo CD server for dedicated [gRPC-ingress]\n    enabled: false\n    # -- Setup up gRPC ingress to work with an AWS ALB\n    isAWSALB: false\n    # -- Additional ingress annotations for dedicated [gRPC-ingress]\n    annotations: {}\n    # -- Additional ingress labels for dedicated [gRPC-ingress]\n    labels: {}\n    # -- Defines which ingress controller will implement the resource [gRPC-ingress]\n    ingressClassName: \"\"\n\n    awsALB:\n      # -- Service type for the AWS ALB gRPC service\n      ## Service Type if isAWSALB is set to true\n      ## Can be of type NodePort or ClusterIP depending on which mode you are\n      ## are running. Instance mode needs type NodePort, IP mode needs type\n      ## ClusterIP\n      ## Ref: https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.2/how-it-works/#ingress-traffic\n      serviceType: NodePort\n      # -- Backend protocol version for the AWS ALB gRPC service\n      ## This tells AWS to send traffic from the ALB using HTTP2. Can use gRPC as well if you want to leverage gRPC specific features\n      backendProtocolVersion: HTTP2\n\n    # -- List of ingress hosts for dedicated [gRPC-ingress]\n    ## Argo Ingress.\n    ## Hostnames must be provided if Ingress is enabled.\n    ## Secrets must be manually created in the namespace\n    ##\n    hosts:\n      []\n      # - argocd.example.com\n\n    # -- List of ingress paths for dedicated [gRPC-ingress]\n    paths:\n      - /\n    # -- Ingress path type for dedicated [gRPC-ingress]. One of `Exact`, `Prefix` or `ImplementationSpecific`\n    pathType: Prefix\n    # -- Additional ingress paths for dedicated [gRPC-ingress]\n    extraPaths:\n      []\n      # - path: /*\n      #   backend:\n      #     serviceName: ssl-redirect\n      #     servicePort: use-annotation\n      ## for Kubernetes \u003e=1.19 (when \"networking.k8s.io/v1\" is used)\n      # - path: /*\n      #   pathType: Prefix\n      #   backend:\n      #     service:\n      #       name: ssl-redirect\n      #       port:\n      #         name: use-annotation\n\n    # -- Ingress TLS configuration for dedicated [gRPC-ingress]\n    tls:\n      []\n      # - secretName: argocd-tls-certificate\n      #   hosts:\n      #     - argocd.example.com\n\n    # -- Uses `server.service.servicePortHttps` instead `server.service.servicePortHttp`\n    https: false\n\n  # Create a OpenShift Route with SSL passthrough for UI and CLI\n  # Consider setting 'hostname' e.g. https://argocd.apps-crc.testing/ using your Default Ingress Controller Domain\n  # Find your domain with: kubectl describe --namespace=openshift-ingress-operator ingresscontroller/default | grep Domain:\n  # If 'hostname' is an empty string \"\" OpenShift will create a hostname for you.\n  route:\n    # -- Enable an OpenShift Route for the Argo CD server\n    enabled: false\n    # -- Openshift Route annotations\n    annotations: {}\n    # -- Hostname of OpenShift Route\n    hostname: \"\"\n    # -- Termination type of Openshift Route\n    termination_type: passthrough\n    # -- Termination policy of Openshift Route\n    termination_policy: None\n\n  # -- Manage Argo CD configmap (Declarative Setup)\n  ## Ref: https://github.com/argoproj/argo-cd/blob/master/docs/operator-manual/argocd-cm.yaml\n  configEnabled: true\n  # -- [General Argo CD configuration]\n  # @default -- See [values.yaml]\n  config:\n    # Argo CD's externally facing base URL (optional). Required when configuring SSO\n    url: \"\"\n    # Argo CD instance label key\n    application.instanceLabelKey: argocd.argoproj.io/instance\n\n    # Enable logs RBAC enforcement\n    # Ref: https://argo-cd.readthedocs.io/en/latest/operator-manual/upgrading/2.3-2.4/#enable-logs-rbac-enforcement\n    server.rbac.log.enforce.enable: \"false\"\n\n    # exec.enabled indicates whether the UI exec feature is enabled. It is disabled by default.\n    # Ref: https://argo-cd.readthedocs.io/en/latest/operator-manual/rbac/#exec-resource\n    exec.enabled: \"false\"\n\n    # admin.enabled indicates whether the admin user is enabled. It is enabled by default.\n    # https://argo-cd.readthedocs.io/en/latest/faq/#how-to-disable-admin-user\n    admin.enabled: \"true\"\n\n    # dex.config: |\n    #   connectors:\n    #     # GitHub example\n    #     - type: github\n    #       id: github\n    #       name: GitHub\n    #       config:\n    #         clientID: aabbccddeeff00112233\n    #         clientSecret: $dex.github.clientSecret # Alternatively $\u003csome_K8S_secret\u003e:dex.github.clientSecret\n    #         orgs:\n    #         - name: your-github-org\n\n    # oidc.config: |\n    #   name: AzureAD\n    #   issuer: https://login.microsoftonline.com/TENANT_ID/v2.0\n    #   clientID: CLIENT_ID\n    #   clientSecret: $oidc.azuread.clientSecret\n    #   requestedIDTokenClaims:\n    #     groups:\n    #       essential: true\n    #   requestedScopes:\n    #     - openid\n    #     - profile\n    #     - email\n\n  # -- Annotations to be added to Argo CD ConfigMap\n  configAnnotations: {}\n\n  # -- Argo CD rbac config ([Argo CD RBAC policy])\n  ## Ref: https://github.com/argoproj/argo-cd/blob/master/docs/operator-manual/rbac.md\n  rbacConfig:\n    {}\n    # policy.csv is a file containing user-defined RBAC policies and role definitions (optional).\n    # Policy rules are in the form:\n    #   p, subject, resource, action, object, effect\n    # Role definitions and bindings are in the form:\n    #   g, subject, inherited-subject\n    # See https://github.com/argoproj/argo-cd/blob/master/docs/operator-manual/rbac.md for additional information.\n    # policy.csv: |\n    #   # Grant all members of the group 'my-org:team-alpha; the ability to sync apps in 'my-project'\n    #   p, my-org:team-alpha, applications, sync, my-project/*, allow\n    #   # Grant all members of 'my-org:team-beta' admins\n    #   g, my-org:team-beta, role:admin\n    # policy.default is the name of the default role which Argo CD will falls back to, when\n    # authorizing API requests (optional). If omitted or empty, users may be still be able to login,\n    # but will see no apps, projects, etc...\n    # policy.default: role:readonly\n    # scopes controls which OIDC scopes to examine during rbac enforcement (in addition to `sub` scope).\n    # If omitted, defaults to: '[groups]'. The scope value can be a string, or a list of strings.\n    # scopes: '[cognito:groups, email]'\n\n  # -- Annotations to be added to Argo CD rbac ConfigMap\n  rbacConfigAnnotations: {}\n\n  # -- Whether or not to create the configmap. If false, it is expected the configmap will be created\n  # by something else. Argo CD will not work if there is no configMap created with the name above.\n  rbacConfigCreate: true\n\n  ## Enable Admin ClusterRole resources.\n  ## Enable if you would like to grant rights to Argo CD to deploy to the local Kubernetes cluster.\n  clusterAdminAccess:\n    # -- Enable RBAC for local cluster deployments\n    enabled: true\n\n  GKEbackendConfig:\n    # -- Enable BackendConfig custom resource for Google Kubernetes Engine\n    enabled: false\n    # -- [BackendConfigSpec]\n    spec: {}\n  #  spec:\n  #    iap:\n  #      enabled: true\n  #      oauthclientCredentials:\n  #        secretName: argocd-secret\n\n  ## Create a Google Managed Certificate for use with the GKE Ingress Controller\n  ## https://cloud.google.com/kubernetes-engine/docs/how-to/managed-certs\n  GKEmanagedCertificate:\n    # -- Enable ManagedCertificate custom resource for Google Kubernetes Engine.\n    enabled: false\n    # -- Domains for the Google Managed Certificate\n    domains:\n    - argocd.example.com\n\n  ## Create a Google FrontendConfig Custom Resource, for use with the GKE Ingress Controller\n  ## https://cloud.google.com/kubernetes-engine/docs/how-to/ingress-features#configuring_ingress_features_through_frontendconfig_parameters\n  GKEfrontendConfig:\n    # -- Enable FrontConfig custom resource for Google Kubernetes Engine\n    enabled: false\n    # -- [FrontendConfigSpec]\n    spec: {}\n  # spec:\n  #   redirectToHttps:\n  #     enabled: true\n  #     responseCodeName: RESPONSE_CODE\n\n  # -- Additional containers to be added to the server pod\n  ## See https://github.com/lemonldap-ng-controller/lemonldap-ng-controller as example.\n  extraContainers: []\n  # - name: my-sidecar\n  #   image: nginx:latest\n  # - name: lemonldap-ng-controller\n  #   image: lemonldapng/lemonldap-ng-controller:0.2.0\n  #   args:\n  #     - /lemonldap-ng-controller\n  #     - --alsologtostderr\n  #     - --configmap=$(POD_NAMESPACE)/lemonldap-ng-configuration\n  #   env:\n  #     - name: POD_NAME\n  #       valueFrom:\n  #         fieldRef:\n  #           fieldPath: metadata.name\n  #     - name: POD_NAMESPACE\n  #       valueFrom:\n  #         fieldRef:\n  #           fieldPath: metadata.namespace\n  #   volumeMounts:\n  #   - name: copy-portal-skins\n  #     mountPath: /srv/var/lib/lemonldap-ng/portal/skins\n\n  # -- Init containers to add to the server pod\n  ## If your target Kubernetes cluster(s) require a custom auth provider executable\n  ## you could use this (and the same in the application controller pod) to bootstrap\n  ## that executable into your Argo CD container\n  initContainers: []\n  #  - name: download-tools\n  #    image: alpine:3.8\n  #    command: [sh, -c]\n  #    args:\n  #      - wget -qO- https://get.helm.sh/helm-v2.16.1-linux-amd64.tar.gz | tar -xvzf - \u0026\u0026\n  #        mv linux-amd64/helm /custom-tools/\n  #    volumeMounts:\n  #      - mountPath: /custom-tools\n  #        name: custom-tools\n  #  volumeMounts:\n  #  - mountPath: /usr/local/bin/helm\n  #    name: custom-tools\n  #    subPath: helm\n\n  extensions:\n    # -- Enable support for extensions\n    ## This function in tech preview stage, do expect unstability or breaking changes in newer versions. Bump image.tag if necessary.\n    enabled: false\n\n    image:\n      # -- Repository to use for extensions image\n      repository: \"ghcr.io/argoproj-labs/argocd-extensions\"\n      # -- Tag to use for extensions image\n      tag: \"v0.1.0\"\n      # -- Image pull policy for extensions\n      imagePullPolicy: IfNotPresent\n\n    # -- Resource limits and requests for the argocd-extensions container\n    resources: {}\n    #  limits:\n    #    cpu: 50m\n    #    memory: 128Mi\n    #  requests:\n    #    cpu: 10m\n    #    memory: 64Mi\n\n    # -- Extensions to be loaded into the server\n    contents: []\n    # - name: argo-rollouts\n    #   url: https://github.com/argoproj-labs/rollout-extension/releases/download/v0.1.0/extension.tar\n\n  pdb:\n    # -- Labels to be added to server pdb\n    labels: {}\n    # -- Annotations to be added to server pdb\n    annotations: {}\n\n    # -- Deploy a Poddisruptionbudget for the server\n    enabled: false\n    # minAvailable: 1\n    # maxUnavailable: 0\n\n  # -- Secrets with credentials to pull images from a private registry\n  imagePullSecrets: []\n\n## Repo Server\nrepoServer:\n  # -- Repo server name\n  name: repo-server\n\n  # -- The number of repo server pods to run\n  replicas: 1\n\n  autoscaling:\n    # -- Enable Horizontal Pod Autoscaler ([HPA]) for the repo server\n    enabled: false\n    # -- Minimum number of replicas for the repo server [HPA]\n    minReplicas: 1\n    # -- Maximum number of replicas for the repo server [HPA]\n    maxReplicas: 5\n    # -- Average CPU utilization percentage for the repo server [HPA]\n    targetCPUUtilizationPercentage: 50\n    # -- Average memory utilization percentage for the repo server [HPA]\n    targetMemoryUtilizationPercentage: 50\n    # -- Configures the scaling behavior of the target in both Up and Down directions.\n    # This is only available on HPA apiVersion `autoscaling/v2beta2` and newer\n    behavior: {}\n      # scaleDown:\n      #  stabilizationWindowSeconds: 300\n      #  policies:\n      #   - type: Pods\n      #     value: 1\n      #     periodSeconds: 180\n      # scaleUp:\n      #   stabilizationWindowSeconds: 300\n      #   policies:\n      #   - type: Pods\n      #     value: 2\n      #     periodSeconds: 60\n\n  image:\n    # -- Repository to use for the repo server\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\" # defaults to global.image.repository\n    # -- Tag to use for the repo server\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\" # defaults to global.image.tag\n    # -- Image pull policy for the repo server\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\" # IfNotPresent\n\n  # -- Additional command line arguments to pass to repo server\n  extraArgs: []\n\n  # -- Environment variables to pass to repo server\n  env: []\n\n  # -- envFrom to pass to repo server\n  # @default -- `[]` (See [values.yaml])\n  envFrom: []\n  # - configMapRef:\n  #     name: config-map-name\n  # - secretRef:\n  #     name: secret-name\n\n  # -- Repo server log format: Either `text` or `json`\n  # @default -- `\"\"` (defaults to global.logging.level)\n  logFormat: \"\"\n  # -- Repo server log level. One of: `debug`, `info`, `warn` or `error`\n  # @default -- `\"\"` (defaults to global.logging.format)\n  logLevel: \"\"\n\n  # -- Annotations to be added to repo server pods\n  podAnnotations: {}\n\n  # -- Labels to be added to repo server pods\n  podLabels: {}\n\n  # -- Configures the repo server port\n  containerPort: 8081\n\n  ## Readiness and liveness probes for default backend\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n  ##\n  readinessProbe:\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n  livenessProbe:\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n\n  # -- Additional volumeMounts to the repo server main container\n  volumeMounts: []\n\n  # -- Additional volumes to the repo server pod\n  volumes: []\n  ## Use init containers to configure custom tooling\n  ## https://argo-cd.readthedocs.io/en/stable/operator-manual/custom_tools/\n  ## When using the volumes \u0026 volumeMounts section bellow, please comment out those above.\n  #  - name: custom-tools\n  #    emptyDir: {}\n\n  # -- [Node selector]\n  nodeSelector: {}\n  # -- [Tolerations] for use with node taints\n  tolerations: []\n  # -- Assign custom [affinity] rules to the deployment\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to the repo server\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n  # - maxSkew: 1\n  #   topologyKey: topology.kubernetes.io/zone\n  #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Priority class for the repo server\n  priorityClassName: \"\"\n\n  # -- Repo server container-level security context\n  containerSecurityContext:\n    {}\n    # capabilities:\n    #   drop:\n    #     - all\n    # readOnlyRootFilesystem: true\n\n  # -- Resource limits and requests for the repo server pods\n  resources: {}\n  #  limits:\n  #    cpu: 50m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 10m\n  #    memory: 64Mi\n\n  ## Repo server service configuration\n  service:\n    # -- Repo server service annotations\n    annotations: {}\n    # -- Repo server service labels\n    labels: {}\n    # -- Repo server service port\n    port: 8081\n    # -- Repo server service port name\n    portName: https-repo-server\n\n  ## Repo server metrics service configuration\n  metrics:\n    # -- Deploy metrics service\n    enabled: false\n    service:\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port\n      servicePort: 8084\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor interval\n      interval: 30s\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\" # \"monitoring\"\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n\n  ## Enable Admin ClusterRole resources.\n  ## Enable if you would like to grant cluster rights to Argo CD repo server.\n  clusterAdminAccess:\n    # -- Enable RBAC for local cluster deployments\n    enabled: false\n  ## Enable Custom Rules for the Repo server's Cluster Role resource\n  ## Enable this and set the rules: to whatever custom rules you want for the Cluster Role resource.\n  ## Defaults to off\n  clusterRoleRules:\n    # -- Enable custom rules for the Repo server's Cluster Role resource\n    enabled: false\n    # -- List of custom rules for the Repo server's Cluster Role resource\n    rules: []\n\n  ## Repo server service account\n  ## If create is set to true, make sure to uncomment the name and update the rbac section below\n  serviceAccount:\n    # -- Create repo server service account\n    create: true\n    # -- Repo server service account name\n    name: \"\" # \"argocd-repo-server\"\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  # -- Additional containers to be added to the repo server pod\n  extraContainers: []\n\n  # -- Repo server rbac rules\n  rbac: []\n  #   - apiGroups:\n  #     - argoproj.io\n  #     resources:\n  #     - applications\n  #     verbs:\n  #     - get\n  #     - list\n  #     - watch\n\n  # Init container to copy argocd binary\n  copyutil:\n    # -- Resource limits and requests for the copyutil initContainer\n    resources: {}\n    #  limits:\n    #    cpu: 50m\n    #    memory: 64Mi\n    #  requests:\n    #    cpu: 10m\n    #    memory: 32Mi\n\n  # -- Init containers to add to the repo server pods\n  initContainers: []\n  #  - name: download-tools\n  #    image: alpine:3.8\n  #    command: [sh, -c]\n  #    args:\n  #      - wget -qO- https://get.helm.sh/helm-v2.16.1-linux-amd64.tar.gz | tar -xvzf - \u0026\u0026\n  #        mv linux-amd64/helm /custom-tools/\n  #    volumeMounts:\n  #      - mountPath: /custom-tools\n  #        name: custom-tools\n  #  volumeMounts:\n  #  - mountPath: /usr/local/bin/helm\n  #    name: custom-tools\n  #    subPath: helm\n\n  pdb:\n    # -- Labels to be added to Repo server pdb\n    labels: {}\n    # -- Annotations to be added to Repo server pdb\n    annotations: {}\n\n    # -- Deploy a Poddisruptionbudget for the Repo server\n    enabled: false\n    # minAvailable: 1\n    # maxUnavailable: 0\n\n  # -- Secrets with credentials to pull images from a private registry\n  imagePullSecrets: []\n\n## Argo Configs\nconfigs:\n  # -- Provide one or multiple [external cluster credentials]\n  # @default -- `[]` (See [values.yaml])\n  ## Ref:\n  ## - https://argo-cd.readthedocs.io/en/stable/operator-manual/declarative-setup/#clusters\n  ## - https://argo-cd.readthedocs.io/en/stable/operator-manual/security/#external-cluster-credentials\n  clusterCredentials: []\n    # - name: mycluster\n    #   server: https://mycluster.com\n    #   labels: {}\n    #   annotations: {}\n    #   config:\n    #     bearerToken: \"\u003cauthentication token\u003e\"\n    #     tlsClientConfig:\n    #       insecure: false\n    #       caData: \"\u003cbase64 encoded certificate\u003e\"\n    # - name: mycluster2\n    #   server: https://mycluster2.com\n    #   labels: {}\n    #   annotations: {}\n    #   namespaces: namespace1,namespace2\n    #   clusterResources: true\n    #   config:\n    #     bearerToken: \"\u003cauthentication token\u003e\"\n    #     tlsClientConfig:\n    #       insecure: false\n    #       caData: \"\u003cbase64 encoded certificate\u003e\"\n\n  # -- GnuPG key ring annotations\n  gpgKeysAnnotations: {}\n  # -- [GnuPG](https://argo-cd.readthedocs.io/en/stable/user-guide/gpg-verification/) keys to add to the key ring\n  # @default -- `{}` (See [values.yaml])\n  gpgKeys: {}\n    # 4AEE18F83AFDEB23: |\n    #     -----BEGIN PGP PUBLIC KEY BLOCK-----\n    #\n    #     mQENBFmUaEEBCACzXTDt6ZnyaVtueZASBzgnAmK13q9Urgch+sKYeIhdymjuMQta\n    #     x15OklctmrZtqre5kwPUosG3/B2/ikuPYElcHgGPL4uL5Em6S5C/oozfkYzhwRrT\n    #     SQzvYjsE4I34To4UdE9KA97wrQjGoz2Bx72WDLyWwctD3DKQtYeHXswXXtXwKfjQ\n    #     7Fy4+Bf5IPh76dA8NJ6UtjjLIDlKqdxLW4atHe6xWFaJ+XdLUtsAroZcXBeWDCPa\n    #     buXCDscJcLJRKZVc62gOZXXtPfoHqvUPp3nuLA4YjH9bphbrMWMf810Wxz9JTd3v\n    #     yWgGqNY0zbBqeZoGv+TuExlRHT8ASGFS9SVDABEBAAG0NUdpdEh1YiAod2ViLWZs\n    #     b3cgY29tbWl0IHNpZ25pbmcpIDxub3JlcGx5QGdpdGh1Yi5jb20+iQEiBBMBCAAW\n    #     BQJZlGhBCRBK7hj4Ov3rIwIbAwIZAQAAmQEH/iATWFmi2oxlBh3wAsySNCNV4IPf\n    #     DDMeh6j80WT7cgoX7V7xqJOxrfrqPEthQ3hgHIm7b5MPQlUr2q+UPL22t/I+ESF6\n    #     9b0QWLFSMJbMSk+BXkvSjH9q8jAO0986/pShPV5DU2sMxnx4LfLfHNhTzjXKokws\n    #     +8ptJ8uhMNIDXfXuzkZHIxoXk3rNcjDN5c5X+sK8UBRH092BIJWCOfaQt7v7wig5\n    #     4Ra28pM9GbHKXVNxmdLpCFyzvyMuCmINYYADsC848QQFFwnd4EQnupo6QvhEVx1O\n    #     j7wDwvuH5dCrLuLwtwXaQh0onG4583p0LGms2Mf5F+Ick6o/4peOlBoZz48=\n    #     =Bvzs\n    #     -----END PGP PUBLIC KEY BLOCK-----\n\n  # -- Known Hosts configmap annotations\n  knownHostsAnnotations: {}\n  knownHosts:\n    data:\n      # -- Known Hosts\n      # @default -- See [values.yaml]\n      ssh_known_hosts: |\n        bitbucket.org ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAubiN81eDcafrgMeLzaFPsw2kNvEcqTKl/VqLat/MaB33pZy0y3rJZtnqwR2qOOvbwKZYKiEO1O6VqNEBxKvJJelCq0dTXWT5pbO2gDXC6h6QDXCaHo6pOHGPUy+YBaGQRGuSusMEASYiWunYN0vCAI8QaXnWMXNMdFP3jHAJH0eDsoiGnLPBlBp4TNm6rYI74nMzgz3B9IikW4WVK+dc8KZJZWYjAuORU3jc1c/NPskD2ASinf8v3xnfXeukU0sJ5N6m5E8VLjObPEO+mN2t/FZTMZLiFqPWc/ALSqnMnnhwrNi2rbfg/rd/IpL8Le3pSBne8+seeFVBoGqzHM9yXw==\n        github.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=\n        github.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl\n        github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ==\n        gitlab.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFSMqzJeV9rUzU4kWitGjeR4PWSa29SPqJ1fVkhtj3Hw9xjLVXVYrU9QlYWrOLXBpQ6KWjbjTDTdDkoohFzgbEY=\n        gitlab.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAfuCHKVTjquxvt6CM6tdG4SLp1Btn/nOeHHE5UOzRdf\n        gitlab.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCsj2bNKTBSpIYDEGk9KxsGh3mySTRgMtXL583qmBpzeQ+jqCMRgBqB98u3z++J1sKlXHWfM9dyhSevkMwSbhoR8XIq/U0tCNyokEi/ueaBMCvbcTHhO7FcwzY92WK4Yt0aGROY5qX2UKSeOvuP4D6TPqKF1onrSzH9bx9XUf2lEdWT/ia1NEKjunUqu1xOB/StKDHMoX4/OKyIzuS0q/T1zOATthvasJFoPrAjkohTyaDUz2LN5JoH839hViyEG82yB+MjcFV5MU3N1l1QL3cVUCh93xSaua1N85qivl+siMkPGbO5xR/En4iEY6K2XPASUEMaieWVNTRCtJ4S8H+9\n        ssh.dev.azure.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H\n        vs-ssh.visualstudio.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H\n  # -- TLS certificate configmap annotations\n  tlsCertsAnnotations: {}\n  # -- TLS certificate\n  # @default -- See [values.yaml]\n  tlsCerts:\n    {}\n    # data:\n    #   argocd.example.com: |\n    #     -----BEGIN CERTIFICATE-----\n    #     MIIF1zCCA7+gAwIBAgIUQdTcSHY2Sxd3Tq/v1eIEZPCNbOowDQYJKoZIhvcNAQEL\n    #     BQAwezELMAkGA1UEBhMCREUxFTATBgNVBAgMDExvd2VyIFNheG9ueTEQMA4GA1UE\n    #     BwwHSGFub3ZlcjEVMBMGA1UECgwMVGVzdGluZyBDb3JwMRIwEAYDVQQLDAlUZXN0\n    #     c3VpdGUxGDAWBgNVBAMMD2Jhci5leGFtcGxlLmNvbTAeFw0xOTA3MDgxMzU2MTda\n    #     Fw0yMDA3MDcxMzU2MTdaMHsxCzAJBgNVBAYTAkRFMRUwEwYDVQQIDAxMb3dlciBT\n    #     YXhvbnkxEDAOBgNVBAcMB0hhbm92ZXIxFTATBgNVBAoMDFRlc3RpbmcgQ29ycDES\n    #     MBAGA1UECwwJVGVzdHN1aXRlMRgwFgYDVQQDDA9iYXIuZXhhbXBsZS5jb20wggIi\n    #     MA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQCv4mHMdVUcafmaSHVpUM0zZWp5\n    #     NFXfboxA4inuOkE8kZlbGSe7wiG9WqLirdr39Ts+WSAFA6oANvbzlu3JrEQ2CHPc\n    #     CNQm6diPREFwcDPFCe/eMawbwkQAPVSHPts0UoRxnpZox5pn69ghncBR+jtvx+/u\n    #     P6HdwW0qqTvfJnfAF1hBJ4oIk2AXiip5kkIznsAh9W6WRy6nTVCeetmIepDOGe0G\n    #     ZJIRn/OfSz7NzKylfDCat2z3EAutyeT/5oXZoWOmGg/8T7pn/pR588GoYYKRQnp+\n    #     YilqCPFX+az09EqqK/iHXnkdZ/Z2fCuU+9M/Zhrnlwlygl3RuVBI6xhm/ZsXtL2E\n    #     Gxa61lNy6pyx5+hSxHEFEJshXLtioRd702VdLKxEOuYSXKeJDs1x9o6cJ75S6hko\n    #     Ml1L4zCU+xEsMcvb1iQ2n7PZdacqhkFRUVVVmJ56th8aYyX7KNX6M9CD+kMpNm6J\n    #     kKC1li/Iy+RI138bAvaFplajMF551kt44dSvIoJIbTr1LigudzWPqk31QaZXV/4u\n    #     kD1n4p/XMc9HYU/was/CmQBFqmIZedTLTtK7clkuFN6wbwzdo1wmUNgnySQuMacO\n    #     gxhHxxzRWxd24uLyk9Px+9U3BfVPaRLiOPaPoC58lyVOykjSgfpgbus7JS69fCq7\n    #     bEH4Jatp/10zkco+UQIDAQABo1MwUTAdBgNVHQ4EFgQUjXH6PHi92y4C4hQpey86\n    #     r6+x1ewwHwYDVR0jBBgwFoAUjXH6PHi92y4C4hQpey86r6+x1ewwDwYDVR0TAQH/\n    #     BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAgEAFE4SdKsX9UsLy+Z0xuHSxhTd0jfn\n    #     Iih5mtzb8CDNO5oTw4z0aMeAvpsUvjJ/XjgxnkiRACXh7K9hsG2r+ageRWGevyvx\n    #     CaRXFbherV1kTnZw4Y9/pgZTYVWs9jlqFOppz5sStkfjsDQ5lmPJGDii/StENAz2\n    #     XmtiPOgfG9Upb0GAJBCuKnrU9bIcT4L20gd2F4Y14ccyjlf8UiUi192IX6yM9OjT\n    #     +TuXwZgqnTOq6piVgr+FTSa24qSvaXb5z/mJDLlk23npecTouLg83TNSn3R6fYQr\n    #     d/Y9eXuUJ8U7/qTh2Ulz071AO9KzPOmleYPTx4Xty4xAtWi1QE5NHW9/Ajlv5OtO\n    #     OnMNWIs7ssDJBsB7VFC8hcwf79jz7kC0xmQqDfw51Xhhk04kla+v+HZcFW2AO9so\n    #     6ZdVHHQnIbJa7yQJKZ+hK49IOoBR6JgdB5kymoplLLiuqZSYTcwSBZ72FYTm3iAr\n    #     jzvt1hxpxVDmXvRnkhRrIRhK4QgJL0jRmirBjDY+PYYd7bdRIjN7WNZLFsgplnS8\n    #     9w6CwG32pRlm0c8kkiQ7FXA6BYCqOsDI8f1VGQv331OpR2Ck+FTv+L7DAmg6l37W\n    #     +LB9LGh4OAp68ImTjqf6ioGKG0RBSznwME+r4nXtT1S/qLR6ASWUS4ViWRhbRlNK\n    #     XWyb96wrUlv+E8I=\n    #     -----END CERTIFICATE-----\n\n  # -- Repository credentials to be used as Templates for other repos\n  ## Creates a secret for each key/value specified below to create repository credentials\n  credentialTemplates: {}\n    # github-enterprise-creds-1:\n    #   url: https://github.com/argoproj\n    #   githubAppID: 1\n    #   githubAppInstallationID: 2\n    #   githubAppEnterpriseBaseUrl: https://ghe.example.com/api/v3\n    #   githubAppPrivateKey: |\n    #     -----BEGIN OPENSSH PRIVATE KEY-----\n    #     ...\n    #     -----END OPENSSH PRIVATE KEY-----\n    # https-creds:\n    #   url: https://github.com/argoproj\n    #   password: my-password\n    #   username: my-username\n    # ssh-creds:\n    #  url: git@github.com:argoproj-labs\n    #  sshPrivateKey: |\n    #    -----BEGIN OPENSSH PRIVATE KEY-----\n    #    ...\n    #    -----END OPENSSH PRIVATE KEY-----\n\n  # -- Annotations to be added to `configs.credentialTemplates` Secret\n  credentialTemplatesAnnotations: {}\n\n  # -- Repositories list to be used by applications\n  ## Creates a secret for each key/value specified below to create repositories\n  ## Note: the last example in the list would use a repository credential template, configured under \"configs.repositoryCredentials\".\n  repositories: {}\n    # istio-helm-repo:\n    #   url: https://storage.googleapis.com/istio-prerelease/daily-build/master-latest-daily/charts\n    #   name: istio.io\n    #   type: helm\n    # private-helm-repo:\n    #   url: https://my-private-chart-repo.internal\n    #   name: private-repo\n    #   type: helm\n    #   password: my-password\n    #   username: my-username\n    # private-repo:\n    #   url: https://github.com/argoproj/private-repo\n\n  # -- Annotations to be added to `configs.repositories` Secret\n  repositoriesAnnotations: {}\n\n  secret:\n    # -- Create the argocd-secret\n    createSecret: true\n    # -- Annotations to be added to argocd-secret\n    annotations: {}\n\n    # -- Shared secret for authenticating GitHub webhook events\n    githubSecret: \"\"\n    # -- Shared secret for authenticating GitLab webhook events\n    gitlabSecret: \"\"\n    # -- Shared secret for authenticating BitbucketServer webhook events\n    bitbucketServerSecret: \"\"\n    # -- UUID for authenticating Bitbucket webhook events\n    bitbucketUUID: \"\"\n    # -- Shared secret for authenticating Gogs webhook events\n    gogsSecret: \"\"\n\n    # -- add additional secrets to be added to argocd-secret\n    ## Custom secrets. Useful for injecting SSO secrets into environment variables.\n    ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/user-management/#sensitive-data-and-sso-client-secrets\n    ## Note that all values must be non-empty.\n    extra:\n      {}\n      # LDAP_PASSWORD: \"mypassword\"\n\n    # -- Argo TLS Data\n    argocdServerTlsConfig:\n      {}\n      # key:\n      # crt: |\n      #   -----BEGIN CERTIFICATE-----\n      #   \u003ccert data\u003e\n      #   -----END CERTIFICATE-----\n      #   -----BEGIN CERTIFICATE-----\n      #   \u003cca cert data\u003e\n      #   -----END CERTIFICATE-----\n\n    # -- Bcrypt hashed admin password\n    ## Argo expects the password in the secret to be bcrypt hashed. You can create this hash with\n    ## `htpasswd -nbBC 10 \"\" $ARGO_PWD | tr -d ':\\n' | sed 's/$2y/$2a/'`\n    argocdServerAdminPassword: \"\"\n    # -- Admin password modification time. Eg. `\"2006-01-02T15:04:05Z\"`\n    # @default -- `\"\"` (defaults to current time)\n    argocdServerAdminPasswordMtime: \"\"\n\n  # -- Define custom [CSS styles] for your argo instance.\n  # This setting will automatically mount the provided CSS and reference it in the argo configuration.\n  # @default -- `\"\"` (See [values.yaml])\n  ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/custom-styles/\n  styles: \"\"\n  # styles: |\n  #  .nav-bar {\n  #    background: linear-gradient(to bottom, #999, #777, #333, #222, #111);\n  #  }\n\nopenshift:\n  # -- enables using arbitrary uid for argo repo server\n  enabled: false\n\napplicationSet:\n  # -- Enable Application Set controller\n  enabled: true\n\n  # -- Application Set controller name string\n  name: applicationset-controller\n\n  # -- The number of controller pods to run\n  replicaCount: 1\n\n  image:\n    # -- Repository to use for the application set controller\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\"\n    # -- Tag to use for the application set controller\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\"\n    # -- Image pull policy for the application set controller\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n\n  args:\n    # -- The default metric address\n    metricsAddr: :8080\n    # -- The default health check port\n    probeBindAddr: :8081\n    # -- The default leader election setting\n    enableLeaderElection: false\n    # -- How application is synced between the generator and the cluster\n    policy: sync\n    # -- Print debug logs\n    debug: false\n    # -- Enable dry run mode\n    dryRun: false\n\n  # -- ApplicationSet controller log format. Either `text` or `json`\n  # @default -- `\"\"` (defaults to global.logging.format)\n  logFormat: \"\"\n  # -- ApplicationSet controller log level. One of: `debug`, `info`, `warn`, `error`\n  # @default -- `\"\"` (defaults to global.logging.level)\n  logLevel: \"\"\n\n  # -- Additional containers to be added to the applicationset controller pod\n  extraContainers: []\n\n  ## Metrics service configuration\n  metrics:\n    # -- Deploy metrics service\n    enabled: false\n    service:\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port\n      servicePort: 8085\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor interval\n      interval: 30s\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\"  # monitoring\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n\n  # -- If defined, uses a Secret to pull an image from a private Docker registry or repository.\n  imagePullSecrets: []\n\n  ## Application set service configuration\n  service:\n    # -- Application set service annotations\n    annotations: {}\n    # -- Application set service labels\n    labels: {}\n    # -- Application set service port\n    port: 7000\n    # -- Application set service port name\n    portName: webhook\n\n  serviceAccount:\n    # -- Specifies whether a service account should be created\n    create: true\n    # -- Annotations to add to the service account\n    annotations: {}\n    # -- The name of the service account to use.\n    # If not set and create is true, a name is generated using the fullname template\n    name: \"\"\n\n  # -- Annotations for the controller pods\n  podAnnotations: {}\n\n  # -- Labels for the controller pods\n  podLabels: {}\n\n  # -- Pod Security Context\n  podSecurityContext: {}\n    # fsGroup: 2000\n\n  # -- Security Context\n  securityContext: {}\n    # capabilities:\n    #   drop:\n    #   - ALL\n    # readOnlyRootFilesystem: true\n    # runAsNonRoot: true\n    # runAsUser: 1000\n\n  # -- Resource limits and requests for the controller pods.\n  resources: {}\n    # We usually recommend not to specify default resources and to leave this as a conscious\n    # choice for the user. This also increases chances charts run on environments with little\n    # resources, such as Minikube. If you do want to specify resources, uncomment the following\n    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n    # limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    # requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n\n  # -- [Node selector]\n  nodeSelector: {}\n\n  # -- [Tolerations] for use with node taints\n  tolerations: []\n\n  # -- Assign custom [affinity] rules\n  affinity: {}\n\n  # -- If specified, indicates the pod's priority. If not specified, the pod priority will be default or zero if there is no default.\n  priorityClassName: \"\"\n\n  # -- List of extra mounts to add (normally used with extraVolumes)\n  extraVolumeMounts: []\n    # - mountPath: /tmp/foobar\n    #   name: foobar\n\n  # -- List of extra volumes to add\n  extraVolumes: []\n    # - name: foobar\n    #   emptyDir: {}\n\n  # -- List of extra cli args to add\n  extraArgs: []\n\n  # -- Environment variables to pass to the controller\n  extraEnv: []\n    # - name: \"MY_VAR\"\n    #   value: \"value\"\n\n  # -- envFrom to pass to the controller\n  # @default -- `[]` (See [values.yaml])\n  extraEnvFrom: []\n    # - configMapRef:\n    #     name: config-map-name\n    # - secretRef:\n    #     name: secret-name\n\n  ## Webhook for the Git Generator\n  ## Ref: https://argocd-applicationset.readthedocs.io/en/master/Generators-Git/#webhook-configuration)\n  webhook:\n    ingress:\n      # -- Enable an ingress resource for Webhooks\n      enabled: false\n      # -- Additional ingress annotations\n      annotations: {}\n      # -- Additional ingress labels\n      labels: {}\n      # -- Defines which ingress controller will implement the resource\n      ingressClassName: \"\"\n\n      # -- List of ingress hosts\n      ## Hostnames must be provided if Ingress is enabled.\n      ## Secrets must be manually created in the namespace\n      hosts: []\n        # - argocd-applicationset.example.com\n\n      # -- List of ingress paths\n      paths:\n        - /api/webhook\n      # -- Ingress path type. One of `Exact`, `Prefix` or `ImplementationSpecific`\n      pathType: Prefix\n      # -- Additional ingress paths\n      extraPaths: []\n        # - path: /*\n        #   backend:\n        #     serviceName: ssl-redirect\n        #     servicePort: use-annotation\n        ## for Kubernetes \u003e=1.19 (when \"networking.k8s.io/v1\" is used)\n        # - path: /*\n        #   pathType: Prefix\n        #   backend:\n        #     service:\n        #       name: ssl-redirect\n        #       port:\n        #         name: use-annotation\n\n      # -- Ingress TLS configuration\n      tls: []\n        # - secretName: argocd-applicationset-tls\n        #   hosts:\n        #     - argocd-applicationset.example.com\n\nnotifications:\n  # -- Enable Notifications controller\n  enabled: true\n\n  # -- Notifications controller name string\n  name: notifications-controller\n\n  # -- Assign custom [affinity] rules\n  affinity: {}\n\n  # -- Argo CD dashboard url; used in place of {{.context.argocdUrl}} in templates\n  argocdUrl:\n\n  image:\n    # -- Repository to use for the notifications controller\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\"\n    # -- Tag to use for the notifications controller\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\"\n    # -- Image pull policy for the notifications controller\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n\n  # -- Secrets with credentials to pull images from a private registry\n  imagePullSecrets: []\n\n  # -- [Node selector]\n  nodeSelector: {}\n\n  # -- The deployment strategy to use to replace existing pods with new ones\n  updateStrategy:\n    type: Recreate\n\n  # -- Define user-defined context\n  ## For more information: https://argocd-notifications.readthedocs.io/en/stable/templates/#defining-user-defined-context\n  context: {}\n    # region: east\n    # environmentName: staging\n\n  secret:\n    # -- Whether helm chart creates controller secret\n    create: true\n\n    # -- key:value pairs of annotations to be added to the secret\n    annotations: {}\n\n    # -- Generic key:value pairs to be inserted into the secret\n    ## Can be used for templates, notification services etc. Some examples given below.\n    ## For more information: https://argocd-notifications.readthedocs.io/en/stable/services/overview/\n    items: {}\n      # slack-token:\n      #   # For more information: https://argocd-notifications.readthedocs.io/en/stable/services/slack/\n\n      # grafana-apiKey:\n      #   # For more information: https://argocd-notifications.readthedocs.io/en/stable/services/grafana/\n\n      # webhooks-github-token:\n\n      # email-username:\n      # email-password:\n        # For more information: https://argocd-notifications.readthedocs.io/en/stable/services/email/\n\n  # -- Application controller log format. Either `text` or `json`\n  # @default -- `\"\"` (defaults to global.logging.format)\n  logFormat: \"\"\n  # -- Application controller log level. One of: `debug`, `info`, `warn`, `error`\n  # @default -- `\"\"` (defaults to global.logging.level)\n  logLevel: \"\"\n\n  # -- Extra arguments to provide to the controller\n  extraArgs: []\n\n  # -- Additional container environment variables\n  extraEnv: []\n\n  # -- List of extra mounts to add (normally used with extraVolumes)\n  extraVolumeMounts: []\n    # - mountPath: /tmp/foobar\n    #   name: foobar\n\n  # -- List of extra volumes to add\n  extraVolumes: []\n    # - name: foobar\n    #   emptyDir: {}\n\n  metrics:\n    # -- Enables prometheus metrics server\n    enabled: false\n    # -- Metrics port\n    port: 9001\n    service:\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n      # namespace: monitoring\n      # interval: 30s\n      # scrapeTimeout: 10s\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n\n  # -- Configures notification services such as slack, email or custom webhook\n  # @default -- See [values.yaml]\n  ## For more information: https://argocd-notifications.readthedocs.io/en/stable/services/overview/\n  notifiers: {}\n    # service.slack: |\n    #   token: $slack-token\n\n  # -- Annotations to be applied to the controller Pods\n  podAnnotations: {}\n\n  # -- Labels to be applied to the controller Pods\n  podLabels: {}\n\n  # -- Pod Security Context\n  securityContext:\n    runAsNonRoot: true\n\n  # -- Container Security Context\n  containerSecurityContext: {}\n\n  # -- Resource limits and requests for the controller\n  resources: {}\n    # limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    # requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n\n  serviceAccount:\n    # -- Specifies whether a service account should be created\n    create: true\n\n    # -- The name of the service account to use.\n    ## If not set and create is true, a name is generated using the fullname template\n    name: argocd-notifications-controller\n\n    # -- Annotations applied to created service account\n    annotations: {}\n\n  cm:\n    # -- Whether helm chart creates controller config map\n    create: true\n\n  # -- Contains centrally managed global application subscriptions\n  ## For more information: https://argocd-notifications.readthedocs.io/en/stable/subscriptions/\n  subscriptions: []\n    # # subscription for on-sync-status-unknown trigger notifications\n    # - recipients:\n    #   - slack:test2\n    #   - email:test@gmail.com\n    #   triggers:\n    #   - on-sync-status-unknown\n    # # subscription restricted to applications with matching labels only\n    # - recipients:\n    #   - slack:test3\n    #   selector: test=true\n    #   triggers:\n    #   - on-sync-status-unknown\n\n  # -- The notification template is used to generate the notification content\n  ## For more information: https://argocd-notifications.readthedocs.io/en/stable/templates/\n  templates: {}\n    # template.app-deployed: |\n    #   email:\n    #     subject: New version of an application {{.app.metadata.name}} is up and running.\n    #   message: |\n    #     {{if eq .serviceType \"slack\"}}:white_check_mark:{{end}} Application {{.app.metadata.name}} is now running new version of deployments manifests.\n    #   slack:\n    #     attachments: |\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\":\"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#18be52\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Revision\",\n    #           \"value\": \"{{.app.status.sync.revision}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n    # template.app-health-degraded: |\n    #   email:\n    #     subject: Application {{.app.metadata.name}} has degraded.\n    #   message: |\n    #     {{if eq .serviceType \"slack\"}}:exclamation:{{end}} Application {{.app.metadata.name}} has degraded.\n    #     Application details: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}.\n    #   slack:\n    #     attachments: |-\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\": \"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#f4c030\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n    # template.app-sync-failed: |\n    #   email:\n    #     subject: Failed to sync application {{.app.metadata.name}}.\n    #   message: |\n    #     {{if eq .serviceType \"slack\"}}:exclamation:{{end}}  The sync operation of application {{.app.metadata.name}} has failed at {{.app.status.operationState.finishedAt}} with the following error: {{.app.status.operationState.message}}\n    #     Sync operation details are available at: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}?operation=true .\n    #   slack:\n    #     attachments: |-\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\":\"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#E96D76\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n    # template.app-sync-running: |\n    #   email:\n    #     subject: Start syncing application {{.app.metadata.name}}.\n    #   message: |\n    #     The sync operation of application {{.app.metadata.name}} has started at {{.app.status.operationState.startedAt}}.\n    #     Sync operation details are available at: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}?operation=true .\n    #   slack:\n    #     attachments: |-\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\":\"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#0DADEA\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n    # template.app-sync-status-unknown: |\n    #   email:\n    #     subject: Application {{.app.metadata.name}} sync status is 'Unknown'\n    #   message: |\n    #     {{if eq .serviceType \"slack\"}}:exclamation:{{end}} Application {{.app.metadata.name}} sync is 'Unknown'.\n    #     Application details: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}.\n    #     {{if ne .serviceType \"slack\"}}\n    #     {{range $c := .app.status.conditions}}\n    #         * {{$c.message}}\n    #     {{end}}\n    #     {{end}}\n    #   slack:\n    #     attachments: |-\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\":\"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#E96D76\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n    # template.app-sync-succeeded: |\n    #   email:\n    #     subject: Application {{.app.metadata.name}} has been successfully synced.\n    #   message: |\n    #     {{if eq .serviceType \"slack\"}}:white_check_mark:{{end}} Application {{.app.metadata.name}} has been successfully synced at {{.app.status.operationState.finishedAt}}.\n    #     Sync operation details are available at: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}?operation=true .\n    #   slack:\n    #     attachments: |-\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\":\"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#18be52\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n\n  # -- [Tolerations] for use with node taints\n  tolerations: []\n\n  # -- The trigger defines the condition when the notification should be sent\n  ## For more information: https://argocd-notifications.readthedocs.io/en/stable/triggers/\n  triggers: {}\n    # trigger.on-deployed: |\n    #   - description: Application is synced and healthy. Triggered once per commit.\n    #     oncePer: app.status.sync.revision\n    #     send:\n    #     - app-deployed\n    #     when: app.status.operationState.phase in ['Succeeded'] and app.status.health.status == 'Healthy'\n    # trigger.on-health-degraded: |\n    #   - description: Application has degraded\n    #     send:\n    #     - app-health-degraded\n    #     when: app.status.health.status == 'Degraded'\n    # trigger.on-sync-failed: |\n    #   - description: Application syncing has failed\n    #     send:\n    #     - app-sync-failed\n    #     when: app.status.operationState.phase in ['Error', 'Failed']\n    # trigger.on-sync-running: |\n    #   - description: Application is being synced\n    #     send:\n    #     - app-sync-running\n    #     when: app.status.operationState.phase in ['Running']\n    # trigger.on-sync-status-unknown: |\n    #   - description: Application status is 'Unknown'\n    #     send:\n    #     - app-sync-status-unknown\n    #     when: app.status.sync.status == 'Unknown'\n    # trigger.on-sync-succeeded: |\n    #   - description: Application syncing has succeeded\n    #     send:\n    #     - app-sync-succeeded\n    #     when: app.status.operationState.phase in ['Succeeded']\n    #\n    # For more information: https://argocd-notifications.readthedocs.io/en/stable/triggers/#default-triggers\n    # defaultTriggers: |\n    #   - on-sync-status-unknown\n\n  ## The optional bot component simplifies managing subscriptions\n  ## For more information: https://argocd-notifications.readthedocs.io/en/stable/bots/overview/\n  bots:\n    slack:\n      # -- Enable slack bot\n      ## You have to set secret.notifiers.slack.signingSecret\n      enabled: false\n\n      # -- The deployment strategy to use to replace existing pods with new ones\n      updateStrategy:\n        type: Recreate\n\n      image:\n        # -- Repository to use for the Slack bot\n        # @default -- `\"\"` (defaults to global.image.repository)\n        repository: \"\"\n        # -- Tag to use for the Slack bot\n        # @default -- `\"\"` (defaults to global.image.tag)\n        tag: \"\"\n        # -- Image pull policy for the Slack bot\n        # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n        imagePullPolicy: \"\"\n\n      # -- Secrets with credentials to pull images from a private registry\n      imagePullSecrets: []\n\n      service:\n        # -- Service annotations for Slack bot\n        annotations: {}\n        # -- Service port for Slack bot\n        port: 80\n        # -- Service type for Slack bot\n        type: LoadBalancer\n\n      serviceAccount:\n        # -- Specifies whether a service account should be created\n        create: true\n\n        # -- The name of the service account to use.\n        ## If not set and create is true, a name is generated using the fullname template\n        name: argocd-notifications-bot\n\n        # -- Annotations applied to created service account\n        annotations: {}\n\n      # -- Pod Security Context\n      securityContext:\n        runAsNonRoot: true\n\n      # -- Container Security Context\n      containerSecurityContext: {}\n\n      # -- Resource limits and requests for the Slack bot\n      resources: {}\n      # limits:\n      #   cpu: 100m\n      #   memory: 128Mi\n      # requests:\n      #   cpu: 100m\n      #   memory: 128Mi\n\n      # -- Assign custom [affinity] rules\n      affinity: {}\n\n      # -- [Tolerations] for use with node taints\n      tolerations: []\n\n      # -- [Node selector]\n      nodeSelector: {}\n\n"
            ],
            "verify": false,
            "version": "5.4.1",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA=="
        }
      ]
    },
    {
      "module": "module.helm-mysql",
      "mode": "managed",
      "type": "helm_release",
      "name": "mysql",
      "provider": "module.helm-mysql.provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "mysql",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": true,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "mysql",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "8.0.30",
                "chart": "mysql",
                "name": "mysql",
                "namespace": "mysql",
                "revision": 1,
                "values": "{\"architecture\":\"standalone\",\"auth\":{\"createDatabase\":true,\"customPasswordFiles\":{},\"database\":\"my_database\",\"existingSecret\":\"\",\"password\":\"\",\"replicationPassword\":\"\",\"replicationUser\":\"replicator\",\"rootPassword\":\"\",\"usePasswordFiles\":false,\"username\":\"\"},\"clusterDomain\":\"cluster.local\",\"commonAnnotations\":{},\"commonLabels\":{},\"diagnosticMode\":{\"args\":[\"infinity\"],\"command\":[\"sleep\"],\"enabled\":false},\"extraDeploy\":[],\"fullnameOverride\":\"\",\"global\":{\"imagePullSecrets\":[],\"imageRegistry\":\"\",\"storageClass\":\"\"},\"image\":{\"debug\":false,\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/mysql\",\"tag\":\"8.0.30-debian-11-r6\"},\"initdbScripts\":{},\"initdbScriptsConfigMap\":\"\",\"kubeVersion\":\"\",\"metrics\":{\"enabled\":false,\"extraArgs\":{\"primary\":[],\"secondary\":[]},\"image\":{\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/mysqld-exporter\",\"tag\":\"0.14.0-debian-11-r23\"},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":120,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"prometheusRule\":{\"additionalLabels\":{},\"enabled\":false,\"namespace\":\"\",\"rules\":[]},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":30,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"resources\":{\"limits\":{},\"requests\":{}},\"service\":{\"annotations\":{\"prometheus.io/port\":\"{{ .Values.metrics.service.port }}\",\"prometheus.io/scrape\":\"true\"},\"port\":9104,\"type\":\"ClusterIP\"},\"serviceMonitor\":{\"annotations\":{},\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"jobLabel\":\"\",\"labels\":{},\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scrapeTimeout\":\"\",\"selector\":{}}},\"nameOverride\":\"\",\"namespaceOverride\":\"\",\"networkPolicy\":{\"allowExternal\":true,\"enabled\":false,\"explicitNamespacesSelector\":{}},\"primary\":{\"affinity\":{},\"args\":[],\"command\":[],\"configuration\":\"[mysqld]\\ndefault_authentication_plugin=mysql_native_password\\nskip-name-resolve\\nexplicit_defaults_for_timestamp\\nbasedir=/opt/bitnami/mysql\\nplugin_dir=/opt/bitnami/mysql/lib/plugin\\nport=3306\\nsocket=/opt/bitnami/mysql/tmp/mysql.sock\\ndatadir=/bitnami/mysql/data\\ntmpdir=/opt/bitnami/mysql/tmp\\nmax_allowed_packet=16M\\nbind-address=0.0.0.0\\npid-file=/opt/bitnami/mysql/tmp/mysqld.pid\\nlog-error=/opt/bitnami/mysql/logs/mysqld.log\\ncharacter-set-server=UTF8\\ncollation-server=utf8_general_ci\\nslow_query_log=0\\nslow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log\\nlong_query_time=10.0\\n\\n[client]\\nport=3306\\nsocket=/opt/bitnami/mysql/tmp/mysql.sock\\ndefault-character-set=UTF8\\nplugin_dir=/opt/bitnami/mysql/lib/plugin\\n\\n[manager]\\nport=3306\\nsocket=/opt/bitnami/mysql/tmp/mysql.sock\\npid-file=/opt/bitnami/mysql/tmp/mysqld.pid\",\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"existingConfigmap\":\"\",\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraFlags\":\"\",\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"initContainers\":[],\"lifecycleHooks\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"name\":\"primary\",\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"pdb\":{\"create\":false,\"maxUnavailable\":\"\",\"minAvailable\":1},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"annotations\":{},\"enabled\":true,\"existingClaim\":\"\",\"selector\":{},\"size\":\"8Gi\",\"storageClass\":\"\"},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podManagementPolicy\":\"\",\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"resources\":{\"limits\":{},\"requests\":{}},\"schedulerName\":\"\",\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"externalTrafficPolicy\":\"Cluster\",\"extraPorts\":[],\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"mysql\":\"\"},\"ports\":{\"mysql\":3306},\"sessionAffinity\":\"None\",\"sessionAffinityConfig\":{},\"type\":\"ClusterIP\"},\"sidecars\":[],\"startupProbe\":{\"enabled\":true,\"failureThreshold\":10,\"initialDelaySeconds\":15,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"terminationGracePeriodSeconds\":\"\",\"tolerations\":[],\"topologySpreadConstraints\":[],\"updateStrategy\":{\"type\":\"RollingUpdate\"}},\"rbac\":{\"create\":false,\"rules\":[]},\"secondary\":{\"affinity\":{},\"args\":[],\"command\":[],\"configuration\":\"[mysqld]\\ndefault_authentication_plugin=mysql_native_password\\nskip-name-resolve\\nexplicit_defaults_for_timestamp\\nbasedir=/opt/bitnami/mysql\\nplugin_dir=/opt/bitnami/mysql/lib/plugin\\nport=3306\\nsocket=/opt/bitnami/mysql/tmp/mysql.sock\\ndatadir=/bitnami/mysql/data\\ntmpdir=/opt/bitnami/mysql/tmp\\nmax_allowed_packet=16M\\nbind-address=0.0.0.0\\npid-file=/opt/bitnami/mysql/tmp/mysqld.pid\\nlog-error=/opt/bitnami/mysql/logs/mysqld.log\\ncharacter-set-server=UTF8\\ncollation-server=utf8_general_ci\\nslow_query_log=0\\nslow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log\\nlong_query_time=10.0\\n\\n[client]\\nport=3306\\nsocket=/opt/bitnami/mysql/tmp/mysql.sock\\ndefault-character-set=UTF8\\nplugin_dir=/opt/bitnami/mysql/lib/plugin\\n\\n[manager]\\nport=3306\\nsocket=/opt/bitnami/mysql/tmp/mysql.sock\\npid-file=/opt/bitnami/mysql/tmp/mysqld.pid\",\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"existingConfigmap\":\"\",\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraFlags\":\"\",\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"initContainers\":[],\"lifecycleHooks\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"name\":\"secondary\",\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"pdb\":{\"create\":false,\"maxUnavailable\":\"\",\"minAvailable\":1},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"annotations\":{},\"enabled\":true,\"selector\":{},\"size\":\"8Gi\",\"storageClass\":\"\"},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podManagementPolicy\":\"\",\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicaCount\":1,\"resources\":{\"limits\":{},\"requests\":{}},\"schedulerName\":\"\",\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"externalTrafficPolicy\":\"Cluster\",\"extraPorts\":[],\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"mysql\":\"\"},\"ports\":{\"mysql\":3306},\"sessionAffinity\":\"None\",\"sessionAffinityConfig\":{},\"type\":\"ClusterIP\"},\"sidecars\":[],\"startupProbe\":{\"enabled\":true,\"failureThreshold\":15,\"initialDelaySeconds\":15,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"terminationGracePeriodSeconds\":\"\",\"tolerations\":[],\"topologySpreadConstraints\":[],\"updateStrategy\":{\"type\":\"RollingUpdate\"}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"\"},\"volumePermissions\":{\"enabled\":false,\"image\":{\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/bitnami-shell\",\"tag\":\"11-debian-11-r23\"},\"resources\":{}}}",
                "version": "9.3.1"
              }
            ],
            "name": "mysql",
            "namespace": "mysql",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://charts.bitnami.com/bitnami",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "## @section Global parameters\n## Global Docker image parameters\n## Please, note that this will override the image parameters, including dependencies, configured to use the global value\n## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass\n\n## @param global.imageRegistry Global Docker image registry\n## @param global.imagePullSecrets Global Docker registry secret names as an array\n## @param global.storageClass Global StorageClass for Persistent Volume(s)\n##\nglobal:\n  imageRegistry: \"\"\n  ## E.g.\n  ## imagePullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  imagePullSecrets: []\n  storageClass: \"\"\n\n## @section Common parameters\n\n## @param kubeVersion Force target Kubernetes version (using Helm capabilities if not set)\n##\nkubeVersion: \"\"\n## @param nameOverride String to partially override common.names.fullname template (will maintain the release name)\n##\nnameOverride: \"\"\n## @param fullnameOverride String to fully override common.names.fullname template\n##\nfullnameOverride: \"\"\n## @param namespaceOverride String to fully override common.names.namespace\n##\nnamespaceOverride: \"\"\n## @param clusterDomain Cluster domain\n##\nclusterDomain: cluster.local\n## @param commonAnnotations Common annotations to add to all MySQL resources (sub-charts are not considered). Evaluated as a template\n##\ncommonAnnotations: {}\n## @param commonLabels Common labels to add to all MySQL resources (sub-charts are not considered). Evaluated as a template\n##\ncommonLabels: {}\n## @param extraDeploy Array with extra yaml to deploy with the chart. Evaluated as a template\n##\nextraDeploy: []\n\n## Enable diagnostic mode in the deployment\n##\ndiagnosticMode:\n  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)\n  ##\n  enabled: false\n  ## @param diagnosticMode.command Command to override all containers in the deployment\n  ##\n  command:\n    - sleep\n  ## @param diagnosticMode.args Args to override all containers in the deployment\n  ##\n  args:\n    - infinity\n\n## @section MySQL common parameters\n\n## Bitnami MySQL image\n## ref: https://hub.docker.com/r/bitnami/mysql/tags/\n## @param image.registry MySQL image registry\n## @param image.repository MySQL image repository\n## @param image.tag MySQL image tag (immutable tags are recommended)\n## @param image.digest MySQL image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n## @param image.pullPolicy MySQL image pull policy\n## @param image.pullSecrets Specify docker-registry secret names as an array\n## @param image.debug Specify if debug logs should be enabled\n##\nimage:\n  registry: docker.io\n  repository: bitnami/mysql\n  tag: 8.0.30-debian-11-r6\n  digest: \"\"\n  ## Specify a imagePullPolicy\n  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n  ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n  ##\n  pullPolicy: IfNotPresent\n  ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ## Example:\n  ## pullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  pullSecrets: []\n  ## Set to true if you would like to see extra information on logs\n  ## It turns BASH and/or NAMI debugging in the image\n  ##\n  debug: false\n## @param architecture MySQL architecture (`standalone` or `replication`)\n##\narchitecture: standalone\n## MySQL Authentication parameters\n##\nauth:\n  ## @param auth.rootPassword Password for the `root` user. Ignored if existing secret is provided\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/mysql#setting-the-root-password-on-first-run\n  ##\n  rootPassword: \"\"\n  ## @param auth.createDatabase Wheter to create the .Values.auth.database or not\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/mysql#creating-a-database-on-first-run\n  ##\n  createDatabase: true\n  ## @param auth.database Name for a custom database to create\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/mysql#creating-a-database-on-first-run\n  ##\n  database: \"my_database\"\n  ## @param auth.username Name for a custom user to create\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/mysql#creating-a-database-user-on-first-run\n  ##\n  username: \"\"\n  ## @param auth.password Password for the new user. Ignored if existing secret is provided\n  ##\n  password: \"\"\n  ## @param auth.replicationUser MySQL replication user\n  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/mysql#setting-up-a-replication-cluster\n  ##\n  replicationUser: replicator\n  ## @param auth.replicationPassword MySQL replication user password. Ignored if existing secret is provided\n  ##\n  replicationPassword: \"\"\n  ## @param auth.existingSecret Use existing secret for password details. The secret has to contain the keys `mysql-root-password`, `mysql-replication-password` and `mysql-password`\n  ## NOTE: When it's set the auth.rootPassword, auth.password, auth.replicationPassword are ignored.\n  ##\n  existingSecret: \"\"\n  ## @param auth.usePasswordFiles Mount credentials as files instead of using an environment variable\n  ##\n  usePasswordFiles: false\n  ## @param auth.customPasswordFiles Use custom password files when `auth.usePasswordFiles` is set to `true`. Define path for keys `root` and `user`, also define `replicator` if `architecture` is set to `replication`\n  ## Example:\n  ## customPasswordFiles:\n  ##   root: /vault/secrets/mysql-root\n  ##   user: /vault/secrets/mysql-user\n  ##   replicator: /vault/secrets/mysql-replicator\n  ##\n  customPasswordFiles: {}\n## @param initdbScripts Dictionary of initdb scripts\n## Specify dictionary of scripts to be run at first boot\n## Example:\n## initdbScripts:\n##   my_init_script.sh: |\n##      #!/bin/bash\n##      echo \"Do something.\"\n##\ninitdbScripts: {}\n## @param initdbScriptsConfigMap ConfigMap with the initdb scripts (Note: Overrides `initdbScripts`)\n##\ninitdbScriptsConfigMap: \"\"\n\n## @section MySQL Primary parameters\n\nprimary:\n  ## @param primary.name Name of the primary database (eg primary, master, leader, ...)\n  ##\n  name: primary\n  ## @param primary.command Override default container command on MySQL Primary container(s) (useful when using custom images)\n  ##\n  command: []\n  ## @param primary.args Override default container args on MySQL Primary container(s) (useful when using custom images)\n  ##\n  args: []\n  ## @param primary.lifecycleHooks for the MySQL Primary container(s) to automate configuration before or after startup\n  ##\n  lifecycleHooks: {}\n  ## @param primary.hostAliases Deployment pod host aliases\n  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  ##\n  hostAliases: []\n  ## @param primary.configuration [string] Configure MySQL Primary with a custom my.cnf file\n  ## ref: https://mysql.com/kb/en/mysql/configuring-mysql-with-mycnf/#example-of-configuration-file\n  ##\n  configuration: |-\n    [mysqld]\n    default_authentication_plugin=mysql_native_password\n    skip-name-resolve\n    explicit_defaults_for_timestamp\n    basedir=/opt/bitnami/mysql\n    plugin_dir=/opt/bitnami/mysql/lib/plugin\n    port=3306\n    socket=/opt/bitnami/mysql/tmp/mysql.sock\n    datadir=/bitnami/mysql/data\n    tmpdir=/opt/bitnami/mysql/tmp\n    max_allowed_packet=16M\n    bind-address=0.0.0.0\n    pid-file=/opt/bitnami/mysql/tmp/mysqld.pid\n    log-error=/opt/bitnami/mysql/logs/mysqld.log\n    character-set-server=UTF8\n    collation-server=utf8_general_ci\n    slow_query_log=0\n    slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log\n    long_query_time=10.0\n\n    [client]\n    port=3306\n    socket=/opt/bitnami/mysql/tmp/mysql.sock\n    default-character-set=UTF8\n    plugin_dir=/opt/bitnami/mysql/lib/plugin\n\n    [manager]\n    port=3306\n    socket=/opt/bitnami/mysql/tmp/mysql.sock\n    pid-file=/opt/bitnami/mysql/tmp/mysqld.pid\n  ## @param primary.existingConfigmap Name of existing ConfigMap with MySQL Primary configuration.\n  ## NOTE: When it's set the 'configuration' parameter is ignored\n  ##\n  existingConfigmap: \"\"\n  ## @param primary.updateStrategy.type Update strategy type for the MySQL primary statefulset\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies\n  ##\n  updateStrategy:\n    type: RollingUpdate\n  ## @param primary.podAnnotations Additional pod annotations for MySQL primary pods\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  ##\n  podAnnotations: {}\n  ## @param primary.podAffinityPreset MySQL primary pod affinity preset. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAffinityPreset: \"\"\n  ## @param primary.podAntiAffinityPreset MySQL primary pod anti-affinity preset. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAntiAffinityPreset: soft\n  ## MySQL Primary node affinity preset\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n  ##\n  nodeAffinityPreset:\n    ## @param primary.nodeAffinityPreset.type MySQL primary node affinity preset type. Ignored if `primary.affinity` is set. Allowed values: `soft` or `hard`\n    ##\n    type: \"\"\n    ## @param primary.nodeAffinityPreset.key MySQL primary node label key to match Ignored if `primary.affinity` is set.\n    ## E.g.\n    ## key: \"kubernetes.io/e2e-az-name\"\n    ##\n    key: \"\"\n    ## @param primary.nodeAffinityPreset.values MySQL primary node label values to match. Ignored if `primary.affinity` is set.\n    ## E.g.\n    ## values:\n    ##   - e2e-az1\n    ##   - e2e-az2\n    ##\n    values: []\n  ## @param primary.affinity Affinity for MySQL primary pods assignment\n  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ## Note: podAffinityPreset, podAntiAffinityPreset, and  nodeAffinityPreset will be ignored when it's set\n  ##\n  affinity: {}\n  ## @param primary.nodeSelector Node labels for MySQL primary pods assignment\n  ## ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n  ## @param primary.tolerations Tolerations for MySQL primary pods assignment\n  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  ##\n  tolerations: []\n  ## @param primary.priorityClassName MySQL primary pods' priorityClassName\n  ##\n  priorityClassName: \"\"\n  ## @param primary.schedulerName Name of the k8s scheduler (other than default)\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  schedulerName: \"\"\n  ## @param primary.terminationGracePeriodSeconds In seconds, time the given to the MySQL primary pod needs to terminate gracefully\n  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods\n  ##\n  terminationGracePeriodSeconds: \"\"\n  ## @param primary.topologySpreadConstraints Topology Spread Constraints for pod assignment\n  ## https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  ## The value is evaluated as a template\n  ##\n  topologySpreadConstraints: []\n  ## @param primary.podManagementPolicy podManagementPolicy to manage scaling operation of MySQL primary pods\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies\n  ##\n  podManagementPolicy: \"\"\n  ## MySQL primary Pod security context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n  ## @param primary.podSecurityContext.enabled Enable security context for MySQL primary pods\n  ## @param primary.podSecurityContext.fsGroup Group ID for the mounted volumes' filesystem\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## MySQL primary container security context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param primary.containerSecurityContext.enabled MySQL primary container securityContext\n  ## @param primary.containerSecurityContext.runAsUser User ID for the MySQL primary container\n  ## @param primary.containerSecurityContext.runAsNonRoot Set MySQL primary container's Security Context runAsNonRoot\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n    runAsNonRoot: true\n  ## MySQL primary container's resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param primary.resources.limits The resources limits for MySQL primary containers\n  ## @param primary.resources.requests The requested resources for MySQL primary containers\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##    cpu: 250m\n    ##    memory: 256Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##    cpu: 250m\n    ##    memory: 256Mi\n    requests: {}\n  ## Configure extra options for liveness probe\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param primary.livenessProbe.enabled Enable livenessProbe\n  ## @param primary.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n  ## @param primary.livenessProbe.periodSeconds Period seconds for livenessProbe\n  ## @param primary.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n  ## @param primary.livenessProbe.failureThreshold Failure threshold for livenessProbe\n  ## @param primary.livenessProbe.successThreshold Success threshold for livenessProbe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 3\n    successThreshold: 1\n  ## Configure extra options for readiness probe\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param primary.readinessProbe.enabled Enable readinessProbe\n  ## @param primary.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n  ## @param primary.readinessProbe.periodSeconds Period seconds for readinessProbe\n  ## @param primary.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n  ## @param primary.readinessProbe.failureThreshold Failure threshold for readinessProbe\n  ## @param primary.readinessProbe.successThreshold Success threshold for readinessProbe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 3\n    successThreshold: 1\n  ## Configure extra options for startupProbe probe\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param primary.startupProbe.enabled Enable startupProbe\n  ## @param primary.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n  ## @param primary.startupProbe.periodSeconds Period seconds for startupProbe\n  ## @param primary.startupProbe.timeoutSeconds Timeout seconds for startupProbe\n  ## @param primary.startupProbe.failureThreshold Failure threshold for startupProbe\n  ## @param primary.startupProbe.successThreshold Success threshold for startupProbe\n  ##\n  startupProbe:\n    enabled: true\n    initialDelaySeconds: 15\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 10\n    successThreshold: 1\n  ## @param primary.customLivenessProbe Override default liveness probe for MySQL primary containers\n  ##\n  customLivenessProbe: {}\n  ## @param primary.customReadinessProbe Override default readiness probe for MySQL primary containers\n  ##\n  customReadinessProbe: {}\n  ## @param primary.customStartupProbe Override default startup probe for MySQL primary containers\n  ##\n  customStartupProbe: {}\n  ## @param primary.extraFlags MySQL primary additional command line flags\n  ## Can be used to specify command line flags, for example:\n  ## E.g.\n  ## extraFlags: \"--max-connect-errors=1000 --max_connections=155\"\n  ##\n  extraFlags: \"\"\n  ## @param primary.extraEnvVars Extra environment variables to be set on MySQL primary containers\n  ## E.g.\n  ## extraEnvVars:\n  ##  - name: TZ\n  ##    value: \"Europe/Paris\"\n  ##\n  extraEnvVars: []\n  ## @param primary.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for MySQL primary containers\n  ##\n  extraEnvVarsCM: \"\"\n  ## @param primary.extraEnvVarsSecret Name of existing Secret containing extra env vars for MySQL primary containers\n  ##\n  extraEnvVarsSecret: \"\"\n  ## Enable persistence using Persistent Volume Claims\n  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/\n  ##\n  persistence:\n    ## @param primary.persistence.enabled Enable persistence on MySQL primary replicas using a `PersistentVolumeClaim`. If false, use emptyDir\n    ##\n    enabled: true\n    ## @param primary.persistence.existingClaim Name of an existing `PersistentVolumeClaim` for MySQL primary replicas\n    ## NOTE: When it's set the rest of persistence parameters are ignored\n    ##\n    existingClaim: \"\"\n    ## @param primary.persistence.storageClass MySQL primary persistent volume storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    storageClass: \"\"\n    ## @param primary.persistence.annotations MySQL primary persistent volume claim annotations\n    ##\n    annotations: {}\n    ## @param primary.persistence.accessModes MySQL primary persistent volume access Modes\n    ##\n    accessModes:\n      - ReadWriteOnce\n    ## @param primary.persistence.size MySQL primary persistent volume size\n    ##\n    size: 8Gi\n    ## @param primary.persistence.selector Selector to match an existing Persistent Volume\n    ## selector:\n    ##   matchLabels:\n    ##     app: my-app\n    ##\n    selector: {}\n  ## @param primary.extraVolumes Optionally specify extra list of additional volumes to the MySQL Primary pod(s)\n  ##\n  extraVolumes: []\n  ## @param primary.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the MySQL Primary container(s)\n  ##\n  extraVolumeMounts: []\n  ## @param primary.initContainers Add additional init containers for the MySQL Primary pod(s)\n  ##\n  initContainers: []\n  ## @param primary.sidecars Add additional sidecar containers for the MySQL Primary pod(s)\n  ##\n  sidecars: []\n  ## MySQL Primary Service parameters\n  ##\n  service:\n    ## @param primary.service.type MySQL Primary K8s service type\n    ##\n    type: ClusterIP\n    ## @param primary.service.ports.mysql MySQL Primary K8s service port\n    ##\n    ports:\n      mysql: 3306\n    ## @param primary.service.nodePorts.mysql MySQL Primary K8s service node port\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n    ##\n    nodePorts:\n      mysql: \"\"\n    ## @param primary.service.clusterIP MySQL Primary K8s service clusterIP IP\n    ## e.g:\n    ## clusterIP: None\n    ##\n    clusterIP: \"\"\n    ## @param primary.service.loadBalancerIP MySQL Primary loadBalancerIP if service type is `LoadBalancer`\n    ## Set the LoadBalancer service type to internal only\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n    ##\n    loadBalancerIP: \"\"\n    ## @param primary.service.externalTrafficPolicy Enable client source IP preservation\n    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n    ##\n    externalTrafficPolicy: Cluster\n    ## @param primary.service.loadBalancerSourceRanges Addresses that are allowed when MySQL Primary service is LoadBalancer\n    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n    ## E.g.\n    ## loadBalancerSourceRanges:\n    ##   - 10.10.10.0/24\n    ##\n    loadBalancerSourceRanges: []\n    ## @param primary.service.extraPorts Extra ports to expose (normally used with the `sidecar` value)\n    ##\n    extraPorts: []\n    ## @param primary.service.annotations Additional custom annotations for MySQL primary service\n    ##\n    annotations: {}\n    ## @param primary.service.sessionAffinity Session Affinity for Kubernetes service, can be \"None\" or \"ClientIP\"\n    ## If \"ClientIP\", consecutive client requests will be directed to the same Pod\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies\n    ##\n    sessionAffinity: None\n    ## @param primary.service.sessionAffinityConfig Additional settings for the sessionAffinity\n    ## sessionAffinityConfig:\n    ##   clientIP:\n    ##     timeoutSeconds: 300\n    ##\n    sessionAffinityConfig: {}\n  ## MySQL primary Pod Disruption Budget configuration\n  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  ##\n  pdb:\n    ## @param primary.pdb.create Enable/disable a Pod Disruption Budget creation for MySQL primary pods\n    ##\n    create: false\n    ## @param primary.pdb.minAvailable Minimum number/percentage of MySQL primary pods that should remain scheduled\n    ##\n    minAvailable: 1\n    ## @param primary.pdb.maxUnavailable Maximum number/percentage of MySQL primary pods that may be made unavailable\n    ##\n    maxUnavailable: \"\"\n  ## @param primary.podLabels MySQL Primary pod label. If labels are same as commonLabels , this will take precedence\n  ##\n  podLabels: {}\n\n## @section MySQL Secondary parameters\n\nsecondary:\n  ## @param secondary.name Name of the secondary database (eg secondary, slave, ...)\n  ##\n  name: secondary\n  ## @param secondary.replicaCount Number of MySQL secondary replicas\n  ##\n  replicaCount: 1\n  ## @param secondary.hostAliases Deployment pod host aliases\n  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n  ##\n  hostAliases: []\n  ## @param secondary.command Override default container command on MySQL Secondary container(s) (useful when using custom images)\n  ##\n  command: []\n  ## @param secondary.args Override default container args on MySQL Secondary container(s) (useful when using custom images)\n  ##\n  args: []\n  ## @param secondary.lifecycleHooks for the MySQL Secondary container(s) to automate configuration before or after startup\n  ##\n  lifecycleHooks: {}\n  ## @param secondary.configuration [string] Configure MySQL Secondary with a custom my.cnf file\n  ## ref: https://mysql.com/kb/en/mysql/configuring-mysql-with-mycnf/#example-of-configuration-file\n  ##\n  configuration: |-\n    [mysqld]\n    default_authentication_plugin=mysql_native_password\n    skip-name-resolve\n    explicit_defaults_for_timestamp\n    basedir=/opt/bitnami/mysql\n    plugin_dir=/opt/bitnami/mysql/lib/plugin\n    port=3306\n    socket=/opt/bitnami/mysql/tmp/mysql.sock\n    datadir=/bitnami/mysql/data\n    tmpdir=/opt/bitnami/mysql/tmp\n    max_allowed_packet=16M\n    bind-address=0.0.0.0\n    pid-file=/opt/bitnami/mysql/tmp/mysqld.pid\n    log-error=/opt/bitnami/mysql/logs/mysqld.log\n    character-set-server=UTF8\n    collation-server=utf8_general_ci\n    slow_query_log=0\n    slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log\n    long_query_time=10.0\n\n    [client]\n    port=3306\n    socket=/opt/bitnami/mysql/tmp/mysql.sock\n    default-character-set=UTF8\n    plugin_dir=/opt/bitnami/mysql/lib/plugin\n\n    [manager]\n    port=3306\n    socket=/opt/bitnami/mysql/tmp/mysql.sock\n    pid-file=/opt/bitnami/mysql/tmp/mysqld.pid\n  ## @param secondary.existingConfigmap Name of existing ConfigMap with MySQL Secondary configuration.\n  ## NOTE: When it's set the 'configuration' parameter is ignored\n  ##\n  existingConfigmap: \"\"\n  ## @param secondary.updateStrategy.type Update strategy type for the MySQL secondary statefulset\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies\n  ##\n  updateStrategy:\n    type: RollingUpdate\n  ## @param secondary.podAnnotations Additional pod annotations for MySQL secondary pods\n  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  ##\n  podAnnotations: {}\n  ## @param secondary.podAffinityPreset MySQL secondary pod affinity preset. Ignored if `secondary.affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ##\n  podAffinityPreset: \"\"\n  ## @param secondary.podAntiAffinityPreset MySQL secondary pod anti-affinity preset. Ignored if `secondary.affinity` is set. Allowed values: `soft` or `hard`\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n  ## Allowed values: soft, hard\n  ##\n  podAntiAffinityPreset: soft\n  ## MySQL Secondary node affinity preset\n  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n  ##\n  nodeAffinityPreset:\n    ## @param secondary.nodeAffinityPreset.type MySQL secondary node affinity preset type. Ignored if `secondary.affinity` is set. Allowed values: `soft` or `hard`\n    ##\n    type: \"\"\n    ## @param secondary.nodeAffinityPreset.key MySQL secondary node label key to match Ignored if `secondary.affinity` is set.\n    ## E.g.\n    ## key: \"kubernetes.io/e2e-az-name\"\n    ##\n    key: \"\"\n    ## @param secondary.nodeAffinityPreset.values MySQL secondary node label values to match. Ignored if `secondary.affinity` is set.\n    ## E.g.\n    ## values:\n    ##   - e2e-az1\n    ##   - e2e-az2\n    ##\n    values: []\n  ## @param secondary.affinity Affinity for MySQL secondary pods assignment\n  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ## Note: podAffinityPreset, podAntiAffinityPreset, and  nodeAffinityPreset will be ignored when it's set\n  ##\n  affinity: {}\n  ## @param secondary.nodeSelector Node labels for MySQL secondary pods assignment\n  ## ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n  ## @param secondary.tolerations Tolerations for MySQL secondary pods assignment\n  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  ##\n  tolerations: []\n  ## @param secondary.priorityClassName MySQL secondary pods' priorityClassName\n  ##\n  priorityClassName: \"\"\n  ## @param secondary.schedulerName Name of the k8s scheduler (other than default)\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  schedulerName: \"\"\n  ## @param secondary.terminationGracePeriodSeconds In seconds, time the given to the MySQL secondary pod needs to terminate gracefully\n  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods\n  ##\n  terminationGracePeriodSeconds: \"\"\n  ## @param secondary.topologySpreadConstraints Topology Spread Constraints for pod assignment\n  ## https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  ## The value is evaluated as a template\n  ##\n  topologySpreadConstraints: []\n  ## @param secondary.podManagementPolicy podManagementPolicy to manage scaling operation of MySQL secondary pods\n  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies\n  ##\n  podManagementPolicy: \"\"\n  ## MySQL secondary Pod security context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n  ## @param secondary.podSecurityContext.enabled Enable security context for MySQL secondary pods\n  ## @param secondary.podSecurityContext.fsGroup Group ID for the mounted volumes' filesystem\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## MySQL secondary container security context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param secondary.containerSecurityContext.enabled MySQL secondary container securityContext\n  ## @param secondary.containerSecurityContext.runAsUser User ID for the MySQL secondary container\n  ## @param secondary.containerSecurityContext.runAsNonRoot Set MySQL secondary container's Security Context runAsNonRoot\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n    runAsNonRoot: true\n  ## MySQL secondary container's resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param secondary.resources.limits The resources limits for MySQL secondary containers\n  ## @param secondary.resources.requests The requested resources for MySQL secondary containers\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##    cpu: 250m\n    ##    memory: 256Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##    cpu: 250m\n    ##    memory: 256Mi\n    requests: {}\n  ## Configure extra options for liveness probe\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param secondary.livenessProbe.enabled Enable livenessProbe\n  ## @param secondary.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n  ## @param secondary.livenessProbe.periodSeconds Period seconds for livenessProbe\n  ## @param secondary.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n  ## @param secondary.livenessProbe.failureThreshold Failure threshold for livenessProbe\n  ## @param secondary.livenessProbe.successThreshold Success threshold for livenessProbe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 3\n    successThreshold: 1\n  ## Configure extra options for readiness probe\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param secondary.readinessProbe.enabled Enable readinessProbe\n  ## @param secondary.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n  ## @param secondary.readinessProbe.periodSeconds Period seconds for readinessProbe\n  ## @param secondary.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n  ## @param secondary.readinessProbe.failureThreshold Failure threshold for readinessProbe\n  ## @param secondary.readinessProbe.successThreshold Success threshold for readinessProbe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 5\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 3\n    successThreshold: 1\n  ## Configure extra options for startupProbe probe\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes\n  ## @param secondary.startupProbe.enabled Enable startupProbe\n  ## @param secondary.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n  ## @param secondary.startupProbe.periodSeconds Period seconds for startupProbe\n  ## @param secondary.startupProbe.timeoutSeconds Timeout seconds for startupProbe\n  ## @param secondary.startupProbe.failureThreshold Failure threshold for startupProbe\n  ## @param secondary.startupProbe.successThreshold Success threshold for startupProbe\n  ##\n  startupProbe:\n    enabled: true\n    initialDelaySeconds: 15\n    periodSeconds: 10\n    timeoutSeconds: 1\n    failureThreshold: 15\n    successThreshold: 1\n  ## @param secondary.customLivenessProbe Override default liveness probe for MySQL secondary containers\n  ##\n  customLivenessProbe: {}\n  ## @param secondary.customReadinessProbe Override default readiness probe for MySQL secondary containers\n  ##\n  customReadinessProbe: {}\n  ## @param secondary.customStartupProbe Override default startup probe for MySQL secondary containers\n  ##\n  customStartupProbe: {}\n  ## @param secondary.extraFlags MySQL secondary additional command line flags\n  ## Can be used to specify command line flags, for example:\n  ## E.g.\n  ## extraFlags: \"--max-connect-errors=1000 --max_connections=155\"\n  ##\n  extraFlags: \"\"\n  ## @param secondary.extraEnvVars An array to add extra environment variables on MySQL secondary containers\n  ## E.g.\n  ## extraEnvVars:\n  ##  - name: TZ\n  ##    value: \"Europe/Paris\"\n  ##\n  extraEnvVars: []\n  ## @param secondary.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for MySQL secondary containers\n  ##\n  extraEnvVarsCM: \"\"\n  ## @param secondary.extraEnvVarsSecret Name of existing Secret containing extra env vars for MySQL secondary containers\n  ##\n  extraEnvVarsSecret: \"\"\n  ## Enable persistence using Persistent Volume Claims\n  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/\n  ##\n  persistence:\n    ## @param secondary.persistence.enabled Enable persistence on MySQL secondary replicas using a `PersistentVolumeClaim`\n    ##\n    enabled: true\n    ## @param secondary.persistence.storageClass MySQL secondary persistent volume storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    storageClass: \"\"\n    ## @param secondary.persistence.annotations MySQL secondary persistent volume claim annotations\n    ##\n    annotations: {}\n    ## @param secondary.persistence.accessModes MySQL secondary persistent volume access Modes\n    ##\n    accessModes:\n      - ReadWriteOnce\n    ## @param secondary.persistence.size MySQL secondary persistent volume size\n    ##\n    size: 8Gi\n    ## @param secondary.persistence.selector Selector to match an existing Persistent Volume\n    ## selector:\n    ##   matchLabels:\n    ##     app: my-app\n    ##\n    selector: {}\n  ## @param secondary.extraVolumes Optionally specify extra list of additional volumes to the MySQL secondary pod(s)\n  ##\n  extraVolumes: []\n  ## @param secondary.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the MySQL secondary container(s)\n  ##\n  extraVolumeMounts: []\n  ## @param secondary.initContainers Add additional init containers for the MySQL secondary pod(s)\n  ##\n  initContainers: []\n  ## @param secondary.sidecars Add additional sidecar containers for the MySQL secondary pod(s)\n  ##\n  sidecars: []\n  ## MySQL Secondary Service parameters\n  ##\n  service:\n    ## @param secondary.service.type MySQL secondary Kubernetes service type\n    ##\n    type: ClusterIP\n    ## @param secondary.service.ports.mysql MySQL secondary Kubernetes service port\n    ##\n    ports:\n      mysql: 3306\n    ## @param secondary.service.nodePorts.mysql MySQL secondary Kubernetes service node port\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n    ##\n    nodePorts:\n      mysql: \"\"\n    ## @param secondary.service.clusterIP MySQL secondary Kubernetes service clusterIP IP\n    ## e.g:\n    ## clusterIP: None\n    ##\n    clusterIP: \"\"\n    ## @param secondary.service.loadBalancerIP MySQL secondary loadBalancerIP if service type is `LoadBalancer`\n    ## Set the LoadBalancer service type to internal only\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n    ##\n    loadBalancerIP: \"\"\n    ## @param secondary.service.externalTrafficPolicy Enable client source IP preservation\n    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n    ##\n    externalTrafficPolicy: Cluster\n    ## @param secondary.service.loadBalancerSourceRanges Addresses that are allowed when MySQL secondary service is LoadBalancer\n    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n    ## E.g.\n    ## loadBalancerSourceRanges:\n    ##   - 10.10.10.0/24\n    ##\n    loadBalancerSourceRanges: []\n    ## @param secondary.service.extraPorts Extra ports to expose (normally used with the `sidecar` value)\n    ##\n    extraPorts: []\n    ## @param secondary.service.annotations Additional custom annotations for MySQL secondary service\n    ##\n    annotations: {}\n    ## @param secondary.service.sessionAffinity Session Affinity for Kubernetes service, can be \"None\" or \"ClientIP\"\n    ## If \"ClientIP\", consecutive client requests will be directed to the same Pod\n    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies\n    ##\n    sessionAffinity: None\n    ## @param secondary.service.sessionAffinityConfig Additional settings for the sessionAffinity\n    ## sessionAffinityConfig:\n    ##   clientIP:\n    ##     timeoutSeconds: 300\n    ##\n    sessionAffinityConfig: {}\n  ## MySQL secondary Pod Disruption Budget configuration\n  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  ##\n  pdb:\n    ## @param secondary.pdb.create Enable/disable a Pod Disruption Budget creation for MySQL secondary pods\n    ##\n    create: false\n    ## @param secondary.pdb.minAvailable Minimum number/percentage of MySQL secondary pods that should remain scheduled\n    ##\n    minAvailable: 1\n    ## @param secondary.pdb.maxUnavailable Maximum number/percentage of MySQL secondary pods that may be made unavailable\n    ##\n    maxUnavailable: \"\"\n  ## @param secondary.podLabels Additional pod labels for MySQL secondary pods\n  ##\n  podLabels: {}\n\n## @section RBAC parameters\n\n## MySQL pods ServiceAccount\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n##\nserviceAccount:\n  ## @param serviceAccount.create Enable the creation of a ServiceAccount for MySQL pods\n  ##\n  create: true\n  ## @param serviceAccount.name Name of the created ServiceAccount\n  ## If not set and create is true, a name is generated using the mysql.fullname template\n  ##\n  name: \"\"\n  ## @param serviceAccount.annotations Annotations for MySQL Service Account\n  ##\n  annotations: {}\n  ## @param serviceAccount.automountServiceAccountToken Automount service account token for the server service account\n  ##\n  automountServiceAccountToken: true\n\n## Role Based Access\n## ref: https://kubernetes.io/docs/admin/authorization/rbac/\n##\nrbac:\n  ## @param rbac.create Whether to create \u0026 use RBAC resources or not\n  ##\n  create: false\n  ## @param rbac.rules Custom RBAC rules to set\n  ## e.g:\n  ## rules:\n  ##   - apiGroups:\n  ##       - \"\"\n  ##     resources:\n  ##       - pods\n  ##     verbs:\n  ##       - get\n  ##       - list\n  ##\n  rules: []\n\n## @section Network Policy\n\n## MySQL Nework Policy configuration\n##\nnetworkPolicy:\n  ## @param networkPolicy.enabled Enable creation of NetworkPolicy resources\n  ##\n  enabled: false\n  ## @param networkPolicy.allowExternal The Policy model to apply.\n  ## When set to false, only pods with the correct\n  ## client label will have network access to the port MySQL is listening\n  ## on. When true, MySQL will accept connections from any source\n  ## (with the correct destination port).\n  ##\n  allowExternal: true\n  ## @param networkPolicy.explicitNamespacesSelector A Kubernetes LabelSelector to explicitly select namespaces from which ingress traffic could be allowed to MySQL\n  ## If explicitNamespacesSelector is missing or set to {}, only client Pods that are in the networkPolicy's namespace\n  ## and that match other criteria, the ones that have the good label, can reach the DB.\n  ## But sometimes, we want the DB to be accessible to clients from other namespaces, in this case, we can use this\n  ## LabelSelector to select these namespaces, note that the networkPolicy's namespace should also be explicitly added.\n  ##\n  ## Example:\n  ## explicitNamespacesSelector:\n  ##   matchLabels:\n  ##     role: frontend\n  ##   matchExpressions:\n  ##    - {key: role, operator: In, values: [frontend]}\n  ##\n  explicitNamespacesSelector: {}\n\n## @section Volume Permissions parameters\n\n## Init containers parameters:\n## volumePermissions: Change the owner and group of the persistent volume mountpoint to runAsUser:fsGroup values from the securityContext section.\n##\nvolumePermissions:\n  ## @param volumePermissions.enabled Enable init container that changes the owner and group of the persistent volume(s) mountpoint to `runAsUser:fsGroup`\n  ##\n  enabled: false\n  ## @param volumePermissions.image.registry Init container volume-permissions image registry\n  ## @param volumePermissions.image.repository Init container volume-permissions image repository\n  ## @param volumePermissions.image.tag Init container volume-permissions image tag (immutable tags are recommended)\n  ## @param volumePermissions.image.digest Init container volume-permissions image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n  ## @param volumePermissions.image.pullPolicy Init container volume-permissions image pull policy\n  ## @param volumePermissions.image.pullSecrets Specify docker-registry secret names as an array\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/bitnami-shell\n    tag: 11-debian-11-r23\n    digest: \"\"\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets.\n    ## Secrets must be manually created in the namespace.\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## e.g:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n  ## @param volumePermissions.resources Init container volume-permissions resources\n  ##\n  resources: {}\n\n## @section Metrics parameters\n\n## Mysqld Prometheus exporter parameters\n##\nmetrics:\n  ## @param metrics.enabled Start a side-car prometheus exporter\n  ##\n  enabled: false\n  ## @param metrics.image.registry Exporter image registry\n  ## @param metrics.image.repository Exporter image repository\n  ## @param metrics.image.tag Exporter image tag (immutable tags are recommended)\n  ## @param metrics.image.digest Exporter image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n  ## @param metrics.image.pullPolicy Exporter image pull policy\n  ## @param metrics.image.pullSecrets Specify docker-registry secret names as an array\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/mysqld-exporter\n    tag: 0.14.0-debian-11-r23\n    digest: \"\"\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets.\n    ## Secrets must be manually created in the namespace.\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## e.g:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n  ## MySQL Prometheus exporter service parameters\n  ## Mysqld Prometheus exporter liveness and readiness probes\n  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\n  ## @param metrics.service.type Kubernetes service type for MySQL Prometheus Exporter\n  ## @param metrics.service.port MySQL Prometheus Exporter service port\n  ## @param metrics.service.annotations [object] Prometheus exporter service annotations\n  ##\n  service:\n    type: ClusterIP\n    port: 9104\n    annotations:\n      prometheus.io/scrape: \"true\"\n      prometheus.io/port: \"{{ .Values.metrics.service.port }}\"\n  ## @param metrics.extraArgs.primary Extra args to be passed to mysqld_exporter on Primary pods\n  ## @param metrics.extraArgs.secondary Extra args to be passed to mysqld_exporter on Secondary pods\n  ## ref: https://github.com/prometheus/mysqld_exporter/\n  ## E.g.\n  ## - --collect.auto_increment.columns\n  ## - --collect.binlog_size\n  ## - --collect.engine_innodb_status\n  ## - --collect.engine_tokudb_status\n  ## - --collect.global_status\n  ## - --collect.global_variables\n  ## - --collect.info_schema.clientstats\n  ## - --collect.info_schema.innodb_metrics\n  ## - --collect.info_schema.innodb_tablespaces\n  ## - --collect.info_schema.innodb_cmp\n  ## - --collect.info_schema.innodb_cmpmem\n  ## - --collect.info_schema.processlist\n  ## - --collect.info_schema.processlist.min_time\n  ## - --collect.info_schema.query_response_time\n  ## - --collect.info_schema.tables\n  ## - --collect.info_schema.tables.databases\n  ## - --collect.info_schema.tablestats\n  ## - --collect.info_schema.userstats\n  ## - --collect.perf_schema.eventsstatements\n  ## - --collect.perf_schema.eventsstatements.digest_text_limit\n  ## - --collect.perf_schema.eventsstatements.limit\n  ## - --collect.perf_schema.eventsstatements.timelimit\n  ## - --collect.perf_schema.eventswaits\n  ## - --collect.perf_schema.file_events\n  ## - --collect.perf_schema.file_instances\n  ## - --collect.perf_schema.indexiowaits\n  ## - --collect.perf_schema.tableiowaits\n  ## - --collect.perf_schema.tablelocks\n  ## - --collect.perf_schema.replication_group_member_stats\n  ## - --collect.slave_status\n  ## - --collect.slave_hosts\n  ## - --collect.heartbeat\n  ## - --collect.heartbeat.database\n  ## - --collect.heartbeat.table\n  ##\n  extraArgs:\n    primary: []\n    secondary: []\n  ## Mysqld Prometheus exporter resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## We usually recommend not to specify default resources and to leave this as a conscious\n  ## choice for the user. This also increases chances charts run on environments with little\n  ## resources, such as Minikube. If you do want to specify resources, uncomment the following\n  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n  ## @param metrics.resources.limits The resources limits for MySQL prometheus exporter containers\n  ## @param metrics.resources.requests The requested resources for MySQL prometheus exporter containers\n  ##\n  resources:\n    ## Example:\n    ## limits:\n    ##    cpu: 100m\n    ##    memory: 256Mi\n    limits: {}\n    ## Examples:\n    ## requests:\n    ##    cpu: 100m\n    ##    memory: 256Mi\n    requests: {}\n  ## Mysqld Prometheus exporter liveness probe\n  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\n  ## @param metrics.livenessProbe.enabled Enable livenessProbe\n  ## @param metrics.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n  ## @param metrics.livenessProbe.periodSeconds Period seconds for livenessProbe\n  ## @param metrics.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n  ## @param metrics.livenessProbe.failureThreshold Failure threshold for livenessProbe\n  ## @param metrics.livenessProbe.successThreshold Success threshold for livenessProbe\n  ##\n  livenessProbe:\n    enabled: true\n    initialDelaySeconds: 120\n    periodSeconds: 10\n    timeoutSeconds: 1\n    successThreshold: 1\n    failureThreshold: 3\n  ## Mysqld Prometheus exporter readiness probe\n  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\n  ## @param metrics.readinessProbe.enabled Enable readinessProbe\n  ## @param metrics.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n  ## @param metrics.readinessProbe.periodSeconds Period seconds for readinessProbe\n  ## @param metrics.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n  ## @param metrics.readinessProbe.failureThreshold Failure threshold for readinessProbe\n  ## @param metrics.readinessProbe.successThreshold Success threshold for readinessProbe\n  ##\n  readinessProbe:\n    enabled: true\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    timeoutSeconds: 1\n    successThreshold: 1\n    failureThreshold: 3\n  ## Prometheus Service Monitor\n  ## ref: https://github.com/coreos/prometheus-operator\n  ##\n  serviceMonitor:\n    ## @param metrics.serviceMonitor.enabled Create ServiceMonitor Resource for scraping metrics using PrometheusOperator\n    ##\n    enabled: false\n    ## @param metrics.serviceMonitor.namespace Specify the namespace in which the serviceMonitor resource will be created\n    ##\n    namespace: \"\"\n    ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in prometheus.\n    ##\n    jobLabel: \"\"\n    ## @param metrics.serviceMonitor.interval Specify the interval at which metrics should be scraped\n    ##\n    interval: 30s\n    ## @param metrics.serviceMonitor.scrapeTimeout Specify the timeout after which the scrape is ended\n    ## e.g:\n    ## scrapeTimeout: 30s\n    ##\n    scrapeTimeout: \"\"\n    ## @param metrics.serviceMonitor.relabelings RelabelConfigs to apply to samples before scraping\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#relabelconfig\n    ##\n    relabelings: []\n    ## @param metrics.serviceMonitor.metricRelabelings MetricRelabelConfigs to apply to samples before ingestion\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#relabelconfig\n    ##\n    metricRelabelings: []\n    ## @param metrics.serviceMonitor.selector ServiceMonitor selector labels\n    ## ref: https://github.com/bitnami/charts/tree/master/bitnami/prometheus-operator#prometheus-configuration\n    ##\n    ## selector:\n    ##   prometheus: my-prometheus\n    ##\n    selector: {}\n    ## @param metrics.serviceMonitor.honorLabels Specify honorLabels parameter to add the scrape endpoint\n    ##\n    honorLabels: false\n    ## @param metrics.serviceMonitor.labels Used to pass Labels that are used by the Prometheus installed in your cluster to select Service Monitors to work with\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec\n    ##\n    labels: {}\n    ## @param metrics.serviceMonitor.annotations ServiceMonitor annotations\n    ##\n    annotations: {}\n\n  ## Prometheus Operator prometheusRule configuration\n  ##\n  prometheusRule:\n    ## @param metrics.prometheusRule.enabled Creates a Prometheus Operator prometheusRule (also requires `metrics.enabled` to be `true` and `metrics.prometheusRule.rules`)\n    ##\n    enabled: false\n    ## @param metrics.prometheusRule.namespace Namespace for the prometheusRule Resource (defaults to the Release Namespace)\n    ##\n    namespace: \"\"\n    ## @param metrics.prometheusRule.additionalLabels Additional labels that can be used so prometheusRule will be discovered by Prometheus\n    ##\n    additionalLabels: {}\n    ## @param metrics.prometheusRule.rules Prometheus Rule definitions\n    ##  - alert: Mysql-Down\n    ##    expr: absent(up{job=\"mysql\"} == 1)\n    ##    for: 5m\n    ##    labels:\n    ##      severity: warning\n    ##      service: mariadb\n    ##    annotations:\n    ##      message: 'MariaDB instance {{`{{`}} $labels.instance {{`}}`}}  is down'\n    ##      summary: MariaDB instance is down\n    ##\n    rules: []\n\n"
            ],
            "verify": false,
            "version": "9.3.1",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "bnVsbA=="
        }
      ]
    }
  ]
}
